{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект. Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 0. Входные данные\n",
    "### Описание проекта\n",
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "В распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных уже сделана.\n",
    "\n",
    "Необходимо построить модель с максимально большим значением *accuracy*. Нужно довести долю правильных ответов по крайней мере до 0.75 и проверить *accuracy* на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Путь к файлу:\n",
    "- /datasets/users_behavior.csv  \n",
    "\n",
    "#### Описание данных таблицы\n",
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Известно:  \n",
    "`сalls` — количество звонков,  \n",
    "`minutes` — суммарная длительность звонков в минутах,  \n",
    "`messages` — количество sms-сообщений,  \n",
    "`mb_used` — израсходованный интернет-трафик в Мб,  \n",
    "`is_ultra` — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).\n",
    "\n",
    "#### План действий\n",
    "1 - Ознакомление с данными.  \n",
    "2 - Разделить исходные данные на обучающую, валидационную и тестовую выборки.  \n",
    "3 - Исследование качество разных моделей, меняя гиперпараметры.  \n",
    "4 - Проверка качество модели на тестовой выборке.  \n",
    "5 - Дополнительно: проверка модели на вменяемость.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 1. Открытие файла с данными и изучение общей информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызовем все необходимые библиотеки для реализации проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл, создадим ДатаФрейм, выведем информацию и первые 10 строк таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "print(df.info())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Предобработка выполнена ранее. Пропусков нет, данные имеют нужный формат. Что позволяет перейти сразу к исследованиям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 2. Разделение исходные данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на 3 части: обучающую, валидационную и тестовую выбороки в пропорциях 3:1:1, используя функцию `train_test_split` из библиетеки *sklearn.model_selection*  \n",
    "Разделим сначала `df` на `df_train` и `df_valid_test`, а потом `df_valid_test` на `df_valid` и `df_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid_test = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры обучающей, валидационной и тестовой выборок на экран и оценим правильность деления на части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 5)\n",
      "(643, 5)\n",
      "(643, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим каждую выборку на `features` -  признаки и `target` — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_test = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Разделили все данные на 3 части. Обучающая - для обучения моделей, Валидационная - для настройки гиперпараметров модели, Тестовая - для окончательной проверки модели на неизвестных данных и оценки качества модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 3. Исследование качества разных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная задача относиться к задачам классификации, в нашем случае бинарной классификации.  \n",
    "Рассмотрим 3 модели:  \n",
    " - **Решающее дерево** DecisionTreeClassifier из библиотеки *sklearn.tree*\n",
    " - **Случайный лес** RandomForestClassifier из библиотеки *sklearn.ensemble*\n",
    " - **Логистическая регрессия** LogisticRegression из библиотеки *sklearn.linear_model*  \n",
    " \n",
    " Сразу введем псевдослучайность для алгоритма обучения, используя генератор псевдослучайных чисел `random_state`. Таким образом модель будет воспринимать данные как случайные, для нас это необходимо , чтобы результаты неизменно получались одинаковыми (другими словами, повторить удачный эксперимент)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Решающее дерево - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель и запишем в переменную **model_decision_tree**, обучим модель используя метод `fit()` на признаках **features_train** и целевом признаке **target_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=12345, splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_decision_tree = DecisionTreeClassifier(random_state=12345)\n",
    "model_decision_tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы предсказать ответы, вызовем метод `predict()`и передать ему таблицу с признаками новых объектов **features_valid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_valid_predictions = model_decision_tree.predict(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем оценку точности предсказания `accuracy_score` для модели, сравнив предсказания **tree_valid_predictions** и правильные ответы **target_valid** в валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713841368584759"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy = accuracy_score(target_valid, tree_valid_predictions)\n",
    "tree_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Меняя гиперпараметры модели, посмотрим как меняется оценка качества **accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_depth` - максимальная глубина дерева. Переберем в цикле значения от 1 до 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.7542768273716952\n",
      "2 : 0.7822706065318819\n",
      "3 : 0.7853810264385692\n",
      "4 : 0.7791601866251944\n",
      "5 : 0.7791601866251944\n",
      "6 : 0.7838258164852255\n",
      "7 : 0.7822706065318819\n",
      "8 : 0.7791601866251944\n",
      "9 : 0.7822706065318819\n",
      "10 : 0.7744945567651633\n",
      "11 : 0.7620528771384136\n",
      "12 : 0.7620528771384136\n",
      "13 : 0.7558320373250389\n",
      "14 : 0.7589424572317263\n",
      "15 : 0.7465007776049767\n",
      "16 : 0.7340590979782271\n",
      "17 : 0.7356143079315708\n",
      "18 : 0.7309486780715396\n",
      "19 : 0.7278382581648523\n",
      "20 : 0.7216174183514774\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,21):\n",
    "    model_decision_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_decision_tree.fit(features_train, target_train)\n",
    "    tree_valid_predictions = model_decision_tree.predict(features_valid)\n",
    "    print(depth,':', accuracy_score(target_valid, tree_valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Качество модели падает при большом увеличении величины глубины дерева, т.к. модель решающее дерево склонно к переобучению. Оптимальным, в данном случае,  `max_depth=3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим критерий Джини на энтропию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=12345, splitter='best')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_decision_tree = DecisionTreeClassifier(random_state=12345, max_depth=3, criterion='entropy')\n",
    "model_decision_tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_valid_predictions = model_decision_tree.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853810264385692"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy = accuracy_score(target_valid, tree_valid_predictions)\n",
    "tree_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Качество модели не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Случайный лес - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель случайный лес(с количеством деревьев `n_estimators=5`) и запишем в переменную **model_random_forest**, обучим модель используя метод `fit()` на признаках **features_train** и целевом признаке **target_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=5,\n",
       "                       n_jobs=None, oob_score=False, random_state=12345,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=5)\n",
    "model_random_forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы предсказать ответы, вызовем метод `predict()`и передать ему таблицу с признаками новых объектов **features_valid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_valid_predictions = model_random_forest.predict(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем оценку точности предсказания `accuracy_score` для модели, сравнив предсказания **forest_valid_predictions** и правильные ответы **target_valid** в валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.749611197511664"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_accuracy = accuracy_score(target_valid, forest_valid_predictions)\n",
    "forest_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Меняя гиперпараметры модели, посмотрим как меняется оценка качества **accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим критерий Джини на энтропию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620528771384136"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=5, criterion='entropy')\n",
    "model_random_forest.fit(features_train, target_train)\n",
    "forest_valid_predictions = model_random_forest.predict(features_valid)\n",
    "forest_accuracy = accuracy_score(target_valid, forest_valid_predictions)\n",
    "forest_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Качество модели изменилось примерно на 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_estimators` - количество деревьев. Переберем в цикле значения от 5 до 100 с шагом 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 0.7620528771384136\n",
      "10 : 0.7853810264385692\n",
      "15 : 0.7807153965785381\n",
      "20 : 0.7838258164852255\n",
      "25 : 0.7869362363919129\n",
      "30 : 0.7947122861586314\n",
      "35 : 0.7931570762052877\n",
      "40 : 0.7947122861586314\n",
      "45 : 0.7962674961119751\n",
      "50 : 0.7993779160186625\n",
      "55 : 0.7931570762052877\n",
      "60 : 0.7916018662519441\n",
      "65 : 0.7916018662519441\n",
      "70 : 0.7884914463452566\n",
      "75 : 0.7884914463452566\n",
      "80 : 0.7916018662519441\n",
      "85 : 0.7884914463452566\n",
      "90 : 0.7900466562986003\n",
      "95 : 0.7884914463452566\n",
      "100 : 0.7869362363919129\n"
     ]
    }
   ],
   "source": [
    "for estimators in range(5,101,5):\n",
    "    model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=estimators, criterion='entropy')\n",
    "    model_random_forest.fit(features_train, target_train)\n",
    "    forest_valid_predictions = model_random_forest.predict(features_valid)\n",
    "    print(estimators,':', accuracy_score(target_valid, forest_valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Качество модели наилучшее при `n_estimators=50`, делее качество не растет, плюс снижает скорость работы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_depth` - максимальная глубина дерева. Переберем в цикле значения от 1 до 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.7589424572317263\n",
      "2 : 0.7869362363919129\n",
      "3 : 0.7884914463452566\n",
      "4 : 0.7884914463452566\n",
      "5 : 0.7993779160186625\n",
      "6 : 0.80248833592535\n",
      "7 : 0.80248833592535\n",
      "8 : 0.7993779160186625\n",
      "9 : 0.8009331259720062\n",
      "10 : 0.7947122861586314\n",
      "11 : 0.7931570762052877\n",
      "12 : 0.7993779160186625\n",
      "13 : 0.7900466562986003\n",
      "14 : 0.7884914463452566\n",
      "15 : 0.7900466562986003\n",
      "16 : 0.7962674961119751\n",
      "17 : 0.7993779160186625\n",
      "18 : 0.7900466562986003\n",
      "19 : 0.7962674961119751\n",
      "20 : 0.7900466562986003\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,21):\n",
    "    model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=50, criterion='entropy', max_depth=depth)\n",
    "    model_random_forest.fit(features_train, target_train)\n",
    "    forest_valid_predictions = model_random_forest.predict(features_valid)\n",
    "    print(depth,':', accuracy_score(target_valid, forest_valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Качество модели не растет при увеличении величины глубины дерева. Оптимальным, в данном случае,  `max_depth=6`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min_samples_split` - гиперпараметр запрещает создавать узлы, в которые попадает слишком мало объектов обучающей выборки.     Переберем в цикле значения от 2 до 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 0.80248833592535\n",
      "3 : 0.80248833592535\n",
      "4 : 0.8009331259720062\n",
      "5 : 0.8040435458786936\n",
      "6 : 0.7993779160186625\n",
      "7 : 0.7993779160186625\n",
      "8 : 0.8040435458786936\n",
      "9 : 0.7993779160186625\n",
      "10 : 0.80248833592535\n"
     ]
    }
   ],
   "source": [
    "for sample in range(2,11):\n",
    "    model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=50, criterion='entropy', max_depth=6, min_samples_split=sample)\n",
    "    model_random_forest.fit(features_train, target_train)\n",
    "    forest_valid_predictions = model_random_forest.predict(features_valid)\n",
    "    print(sample,':', accuracy_score(target_valid, forest_valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Качество модели оптимально при `min_samples_split=5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем все гиперпараметры Случайного леса и выведем итоговое качество модели:  \n",
    "`n_estimators=50`, `criterion='entropy'`, `max_depth=6`, `min_samples_split=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8040435458786936"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=50, criterion='entropy', max_depth=6, min_samples_split=5)\n",
    "model_random_forest.fit(features_train, target_train)\n",
    "forest_valid_predictions = model_random_forest.predict(features_valid)\n",
    "accuracy_score(target_valid, forest_valid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Логистическая регрессия - LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель Логистическая регрессия и запишем в переменную **logistic_model**, обучим модель используя метод `fit()` на признаках **features_train** и целевом признаке **target_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state=12345)\n",
    "logistic_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы предсказать ответы, вызовем метод `predict()`и передать ему таблицу с признаками новых объектов **features_valid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_valid_predictions = logistic_model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем оценку точности предсказания `accuracy_score` для модели, сравнив предсказания **logistic_valid_predictions** и правильные ответы **target_valid** в валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7589424572317263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_accuracy = accuracy_score(target_valid, logistic_valid_predictions)\n",
    "logistic_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Меняя гиперпараметры модели, посмотрим как меняется оценка качества **accuracy**  \n",
    "Данная модель имеет мало гиперпараметров для настройки, изменим `solver='liblinear'`, `warm_start=True`, `multi_class='ovr'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7589424572317263"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state=12345, solver='liblinear', warm_start=True, multi_class='ovr')\n",
    "logistic_model.fit(features_train, target_train)\n",
    "logistic_valid_predictions = logistic_model.predict(features_valid)\n",
    "logistic_accuracy = accuracy_score(target_valid, logistic_valid_predictions)\n",
    "logistic_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Качество модели не стало лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> На качество обученной модели проверили Решающее дерево, Случайный лес и Логистическую регрессию. Лучшие показатели, с учетом всех настроек у Случайного леса, что не удивительно, использую сразу несколько независимых деревьев и определяя результат голосованием получается самое точное предсказание, но скорость работы становиться медленее, чем больше деревьев в лесу.  \n",
    "Далее будем использовать модель Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 4. Проверка качество модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как модель определена и ее гиперпараметры выяснены, объеденим обучающую и валидационную выборку, используя метод `.append`, для того чтобы обучить модель еще немного лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2571, 5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_valid = df_train.append(df_valid, ignore_index=True)\n",
    "df_train_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Обучающая выборка стала на 20% больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим обучающую выборку `df_train_valid` на признаки `features_train_valid` и целевой признак `target_train_valid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid = df_train_valid.drop(['is_ultra'], axis=1)\n",
    "target_train_valid = df_train_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново обучим модель Случайный лес `model_random_forest` с настроенными гиперпараметрами на расширенной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=12345,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_forest = RandomForestClassifier(random_state=12345, n_estimators=50, criterion='entropy', max_depth=6, min_samples_split=5)\n",
    "model_random_forest.fit(features_train_valid, target_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы предсказать ответы, вызовем метод `predict()`и передать ему таблицу с признаками новых объектов **features_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_valid_predictions = model_random_forest.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем оценку точности предсказания `accuracy_score` для модели, сравнив предсказания **forest_valid_predictions** и правильные ответы **target_test** в тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8211508553654744"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_accuracy = accuracy_score(target_test, forest_valid_predictions)\n",
    "forest_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же оценку качества модели можно получить вызвав функцию `.score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8211508553654744"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_forest.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим значение качества модели на обучающей выборке: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245818747569039"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_forest.score(features_train_valid, target_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Качество на обучающей выборке и тестовой почти равны, что говорит о отсутствии переобучения у модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> На тестовой выборке модель показала точность 82%, что говорит о хорошем качестве предсказания результатов на незнакомых данных. Так же модель не переучена, т.к. на тестовой и обучающей выборке результаты почти равны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 5. Дополнительно: проверка модели на вменяемость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы получить «случайные» результаты, воспользуемся DummyClassifier. Полученные им результаты абсолютно случайные.  \n",
    "Стратегию выставим `strategy='uniform'` как самую случайную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy='uniform', random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на наших данных и посчитаем точность предсказания: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5038880248833593"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model.fit(features_train_valid, target_train_valid)\n",
    "dummy_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка предсказания модели равна 0.5. То есть с вероятностью 50/50 она предсказывает результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Результаты метрик для модели Случайный лес и DummyClassifier, отличаются на 30%. Это говорит о том, что обученная модель работает лучше, чем «абсолютно случайные результаты»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 6. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Модель Случайный лес показала самые лучшие результаты из 3 моделей.\n",
    "- Используя десятки Решающих независимых деревьев, модель выбирает оптимальный вариант.\n",
    "- Большое количество настроек гиперпараметров позволяет усовершенствовать модель\n",
    "- Полученные значения качества модели в 82% говорит о хорошем предсказании.  \n",
    "- Построенная модель для задачи классификации, сможет подобрать для пользователей, пользующихся архивными тарифами, более подходящий тариф («Смарт» или «Ультра»).  \n",
    "- Проанализировав поведение клиентов: тратах минут, сообщений и интернет трафика, модель в 4 из 5 случаев предскажет верный тариф для пользователя. \n",
    "- Модель подходит как система \"Рекомендации тарифов\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
