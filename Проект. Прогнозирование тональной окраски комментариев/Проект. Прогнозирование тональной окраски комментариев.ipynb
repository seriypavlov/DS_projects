{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект. Прогнозирование тональной окраски комментариев\n",
    "## Глава 0. Входные данные\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Требуется модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели. \n",
    "3. Сделайть выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "#### Путь к файлу:\n",
    "- /datasets/toxic_comments.csv\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Признаки:  \n",
    "- `text` — текст комментария  \n",
    "\n",
    "Целевой признак:\n",
    "- `toxic` — оценка токсичности комментария (1 - да, 0 - нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызовем основные библиотеки, необходимые для реализации проекта, более специфичные по ходу выполнения проекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл, создадим ДатаФрейм, выведем таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('/datasets/toxic_comments.csv') # для загрузки из облака\n",
    "df = pd.read_csv('toxic_comments.csv') # локально\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем информацию о таблице через метод `.info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевого признака, построив гистограмму и подсчитав уникальные значения(через методы `.hist()` и `.value_counts()` соответственно):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутствует дисбаланс в целевом признаке. Количество токсичных комментариев значительно меньше. Необходимо это учеть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем извлечь признаки из текста, упростим его.  \n",
    "Воспользуемся Лемматизацией — приведение слова к начальной форме (лемме).  \n",
    "Применим лемматизатор Wordnet из NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале необходимо загрузить библиотеку и необходимые компоненты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Сергей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Сергей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы лемматизировать, нужно создать экземпляр WordNetLemmatizer() и вызвать функцию lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы найти правильный POS-тег для каждого слова, сопоставим его с правильным входным символом, который принимает WordnetLemmatizer, и передадим его в качестве второго аргумента в lemmatize().  \n",
    "В nltk для этого есть метод nltk.pos_tag(). Он принимает список слов, а возвращает кортеж с тегом POS. Ключевым моментом здесь является сопоставление POS-тегов NLTK с форматом, принятым лемматизатором wordnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся готовыми и напишем функции для лемматизации текста:  \n",
    "**get_wordnet_pos(word)** - возвращает  POS тэг для слова(к какой части речи относится слово)  \n",
    "**clear_text(text)** - приводит к нижнему регистру и очишает от символом, кроме букв английского алфавита(через re)  \n",
    "**lemmatize(text)** - проводит лемматизацию текста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_list = nltk.word_tokenize(text)\n",
    "    lemm_text = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lemm_list])      \n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear_text = clear_text.lower().split()\n",
    "    return ' '.join(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что функции работают корректно на тексте первой строке обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits make under my username hardcore metallica fan be revert they weren t vandalism just closure on some gas after i vote at new york doll fac and please don t remove the template from the talk page since i m retire now'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(clear_text(df.loc[0, 'text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем лемматизацию для всего столбца:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 42min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df['text'].apply(lambda text: lemmatize(clear_text(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем полученный результат и соотношение меток целевого признака в тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='toxic', data=df, palette='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы сохранить результаты лемматизации и не запускать снова трудоемкий процесс, сохраним в csv и будем использовать его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lemm_toxic_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lemm_toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на 2 части: обучающую и тестовую выбороки в пропорциях 4:1, используя функцию `train_test_split` из библиетеки `sklearn.model_selection`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    df['lemm_text'], df['toxic'], test_size=0.25, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры матриц и векторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119678,), (39893,), (119678,), (39893,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape, train_target.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создададим корпуса слов для обучающей и тестовой выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train_features.values.astype('U')\n",
    "test_corpus = test_features.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы почистить мешок слов, найдём стоп-слова. Используем пакет **stopwords**, который находится в модуле **nltk.corpus** библиотеки **nltk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Сергей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычислим TF-IDF для корпуса текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитать TF-IDF можно и в библиотеке **sklearn**. Класс `TfidfVectorizer()` в модуле **sklearn.feature_extraction.text**. Импортируем его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счётчик, указав в нём стоп-слова, вызовем функцию `.fit_transform()` для обучающей выборки и `.transform()` для тестовой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "train_tf_idf = count_tf_idf.fit_transform(train_corpus)\n",
    "test_tf_idf = count_tf_idf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры получившихся матриц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей матрицы: (119678, 128432)\n",
      "Размер тестовой матрицы: (39893, 128432)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер обучающей матрицы:\", train_tf_idf.shape), \n",
    "print(\"Размер тестовой матрицы:\", test_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию `scoring(fitted_model)` для определения метрики f1_score для тестовой выбороки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(fitted_model):\n",
    "    test_pred = fitted_model.predict(test_tf_idf)\n",
    "    test_f1 = f1_score(test_target, test_pred)\n",
    "    \n",
    "    print('F1 на тестовой выборке: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">В процессе загрузки и обработки данных обнаружили:\n",
    "- В данных присутствовал дисбаланс целевого признака\n",
    "- NLTK библиотека позволила преобразоваться тексты в векторный вид, пригодный для обучения моделей.\n",
    "- TF-IDF существенно увеличил количество признаков, равное количеству в мешке слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим несколько моделей и оценим полученные результаты.  \n",
    "Модели для обучения:\n",
    "- **LogisticRegression**\n",
    "- **XGBClassifier**\n",
    "- **CatBoostClassifier**\n",
    "- **LGBMClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подбора гиперпараметров импортируем **GridSearchCV**, для кросс-валидации при подборе гиперпараметров **ShuffleSplit**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратегия кросс-валидации для подбора параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=2, test_size=0.25, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Обучим логистическую регресиию **LogisticRegression** как базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=17, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {'C': np.linspace(0.0001, 100, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=17, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000e-04, 1.11112e+01, 2.22223e+01, 3.33334e+01, 4.44445e+01,\n",
       "       5.55556e+01, 6.66667e+01, 7.77778e+01, 8.88889e+01, 1.00000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_grid = GridSearchCV(log_reg, log_reg_params, scoring='f1')\n",
    "log_reg_grid.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 11.1112}\n",
      "best scores:  0.7575399592857313\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', log_reg_grid.best_params_)\n",
    "print('best scores: ', log_reg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=11.1112, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=17, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.761\n",
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(log_reg_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучим модель градиентного бустинга  XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_params = {'n_estimators': [100, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_con...\n",
       "                                     n_estimators=100, n_jobs=-1,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=17, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=False,\n",
       "                                     verbosity=None),\n",
       "             iid='warn', n_jobs=None, param_grid={'n_estimators': [100, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf_grid = GridSearchCV(xgb_clf, xgb_clf_params, scoring='f1')\n",
    "xgb_clf_grid.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'n_estimators': 500}\n",
      "best scores:  0.7624070342646422\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', xgb_clf_grid.best_params_)\n",
    "print('best scores: ', xgb_clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=17, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.775\n",
      "Wall time: 805 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(xgb_clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Обучим модель градиентного бустинга  CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86305     0\n",
       "86000     0\n",
       "122621    0\n",
       "150823    0\n",
       "128349    0\n",
       "         ..\n",
       "25631     0\n",
       "125680    0\n",
       "42297     0\n",
       "34959     1\n",
       "64753     0\n",
       "Name: toxic, Length: 119678, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight = round((len(train_target[train_target == 0]) / \n",
    "                          len(train_target[train_target == 1])), 3)\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoost_clf = CatBoostClassifier(random_state=17, iterations=500, scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.150069\n",
      "0:\tlearn: 0.6282730\ttotal: 2.65s\tremaining: 22m 1s\n",
      "1:\tlearn: 0.5867189\ttotal: 4.68s\tremaining: 19m 24s\n",
      "2:\tlearn: 0.5611878\ttotal: 6.07s\tremaining: 16m 44s\n",
      "3:\tlearn: 0.5478580\ttotal: 7.29s\tremaining: 15m 3s\n",
      "4:\tlearn: 0.5333440\ttotal: 8.49s\tremaining: 14m\n",
      "5:\tlearn: 0.5213615\ttotal: 9.71s\tremaining: 13m 19s\n",
      "6:\tlearn: 0.5105712\ttotal: 10.9s\tremaining: 12m 46s\n",
      "7:\tlearn: 0.5030787\ttotal: 12.1s\tremaining: 12m 22s\n",
      "8:\tlearn: 0.4941392\ttotal: 13.3s\tremaining: 12m 4s\n",
      "9:\tlearn: 0.4885992\ttotal: 14.5s\tremaining: 11m 49s\n",
      "10:\tlearn: 0.4827064\ttotal: 15.7s\tremaining: 11m 36s\n",
      "11:\tlearn: 0.4786722\ttotal: 16.8s\tremaining: 11m 25s\n",
      "12:\tlearn: 0.4734499\ttotal: 18s\tremaining: 11m 15s\n",
      "13:\tlearn: 0.4674460\ttotal: 19.2s\tremaining: 11m 7s\n",
      "14:\tlearn: 0.4606905\ttotal: 20.4s\tremaining: 11m\n",
      "15:\tlearn: 0.4572097\ttotal: 21.7s\tremaining: 10m 56s\n",
      "16:\tlearn: 0.4536339\ttotal: 23s\tremaining: 10m 52s\n",
      "17:\tlearn: 0.4499871\ttotal: 24.3s\tremaining: 10m 50s\n",
      "18:\tlearn: 0.4463375\ttotal: 25.6s\tremaining: 10m 49s\n",
      "19:\tlearn: 0.4428376\ttotal: 27.1s\tremaining: 10m 49s\n",
      "20:\tlearn: 0.4401294\ttotal: 28.5s\tremaining: 10m 50s\n",
      "21:\tlearn: 0.4358544\ttotal: 30s\tremaining: 10m 51s\n",
      "22:\tlearn: 0.4332723\ttotal: 31.4s\tremaining: 10m 50s\n",
      "23:\tlearn: 0.4308026\ttotal: 32.6s\tremaining: 10m 47s\n",
      "24:\tlearn: 0.4278073\ttotal: 33.9s\tremaining: 10m 43s\n",
      "25:\tlearn: 0.4241667\ttotal: 35.2s\tremaining: 10m 41s\n",
      "26:\tlearn: 0.4207272\ttotal: 36.4s\tremaining: 10m 38s\n",
      "27:\tlearn: 0.4181620\ttotal: 37.7s\tremaining: 10m 35s\n",
      "28:\tlearn: 0.4162075\ttotal: 39s\tremaining: 10m 33s\n",
      "29:\tlearn: 0.4143591\ttotal: 40.3s\tremaining: 10m 30s\n",
      "30:\tlearn: 0.4125384\ttotal: 41.6s\tremaining: 10m 28s\n",
      "31:\tlearn: 0.4106073\ttotal: 42.8s\tremaining: 10m 26s\n",
      "32:\tlearn: 0.4085624\ttotal: 44.1s\tremaining: 10m 23s\n",
      "33:\tlearn: 0.4064185\ttotal: 45.4s\tremaining: 10m 21s\n",
      "34:\tlearn: 0.4048409\ttotal: 46.7s\tremaining: 10m 20s\n",
      "35:\tlearn: 0.4037190\ttotal: 48s\tremaining: 10m 19s\n",
      "36:\tlearn: 0.4015128\ttotal: 49.3s\tremaining: 10m 17s\n",
      "37:\tlearn: 0.3999772\ttotal: 50.6s\tremaining: 10m 15s\n",
      "38:\tlearn: 0.3969828\ttotal: 51.9s\tremaining: 10m 13s\n",
      "39:\tlearn: 0.3955323\ttotal: 53.2s\tremaining: 10m 11s\n",
      "40:\tlearn: 0.3941313\ttotal: 54.6s\tremaining: 10m 11s\n",
      "41:\tlearn: 0.3922999\ttotal: 55.9s\tremaining: 10m 9s\n",
      "42:\tlearn: 0.3902301\ttotal: 57.4s\tremaining: 10m 9s\n",
      "43:\tlearn: 0.3885670\ttotal: 58.8s\tremaining: 10m 9s\n",
      "44:\tlearn: 0.3869389\ttotal: 1m\tremaining: 10m 9s\n",
      "45:\tlearn: 0.3847213\ttotal: 1m 1s\tremaining: 10m 7s\n",
      "46:\tlearn: 0.3830749\ttotal: 1m 2s\tremaining: 10m 5s\n",
      "47:\tlearn: 0.3812973\ttotal: 1m 4s\tremaining: 10m 4s\n",
      "48:\tlearn: 0.3795932\ttotal: 1m 5s\tremaining: 10m 2s\n",
      "49:\tlearn: 0.3783296\ttotal: 1m 6s\tremaining: 10m\n",
      "50:\tlearn: 0.3769377\ttotal: 1m 8s\tremaining: 9m 59s\n",
      "51:\tlearn: 0.3761619\ttotal: 1m 9s\tremaining: 9m 58s\n",
      "52:\tlearn: 0.3752650\ttotal: 1m 10s\tremaining: 9m 57s\n",
      "53:\tlearn: 0.3744454\ttotal: 1m 12s\tremaining: 9m 55s\n",
      "54:\tlearn: 0.3733249\ttotal: 1m 13s\tremaining: 9m 52s\n",
      "55:\tlearn: 0.3724626\ttotal: 1m 14s\tremaining: 9m 49s\n",
      "56:\tlearn: 0.3706806\ttotal: 1m 15s\tremaining: 9m 46s\n",
      "57:\tlearn: 0.3695354\ttotal: 1m 16s\tremaining: 9m 44s\n",
      "58:\tlearn: 0.3680350\ttotal: 1m 17s\tremaining: 9m 41s\n",
      "59:\tlearn: 0.3668532\ttotal: 1m 19s\tremaining: 9m 39s\n",
      "60:\tlearn: 0.3652253\ttotal: 1m 20s\tremaining: 9m 37s\n",
      "61:\tlearn: 0.3642142\ttotal: 1m 21s\tremaining: 9m 34s\n",
      "62:\tlearn: 0.3628135\ttotal: 1m 22s\tremaining: 9m 32s\n",
      "63:\tlearn: 0.3614933\ttotal: 1m 23s\tremaining: 9m 30s\n",
      "64:\tlearn: 0.3605761\ttotal: 1m 24s\tremaining: 9m 27s\n",
      "65:\tlearn: 0.3594670\ttotal: 1m 26s\tremaining: 9m 26s\n",
      "66:\tlearn: 0.3579687\ttotal: 1m 27s\tremaining: 9m 24s\n",
      "67:\tlearn: 0.3571716\ttotal: 1m 28s\tremaining: 9m 23s\n",
      "68:\tlearn: 0.3563647\ttotal: 1m 29s\tremaining: 9m 21s\n",
      "69:\tlearn: 0.3553682\ttotal: 1m 31s\tremaining: 9m 19s\n",
      "70:\tlearn: 0.3540022\ttotal: 1m 32s\tremaining: 9m 17s\n",
      "71:\tlearn: 0.3526922\ttotal: 1m 33s\tremaining: 9m 16s\n",
      "72:\tlearn: 0.3518944\ttotal: 1m 35s\tremaining: 9m 16s\n",
      "73:\tlearn: 0.3510237\ttotal: 1m 36s\tremaining: 9m 15s\n",
      "74:\tlearn: 0.3498365\ttotal: 1m 37s\tremaining: 9m 14s\n",
      "75:\tlearn: 0.3489818\ttotal: 1m 39s\tremaining: 9m 14s\n",
      "76:\tlearn: 0.3477708\ttotal: 1m 40s\tremaining: 9m 12s\n",
      "77:\tlearn: 0.3468529\ttotal: 1m 41s\tremaining: 9m 10s\n",
      "78:\tlearn: 0.3458854\ttotal: 1m 43s\tremaining: 9m 9s\n",
      "79:\tlearn: 0.3450676\ttotal: 1m 44s\tremaining: 9m 7s\n",
      "80:\tlearn: 0.3439182\ttotal: 1m 45s\tremaining: 9m 6s\n",
      "81:\tlearn: 0.3430717\ttotal: 1m 46s\tremaining: 9m 4s\n",
      "82:\tlearn: 0.3416362\ttotal: 1m 48s\tremaining: 9m 3s\n",
      "83:\tlearn: 0.3408465\ttotal: 1m 49s\tremaining: 9m 2s\n",
      "84:\tlearn: 0.3395626\ttotal: 1m 50s\tremaining: 9m 1s\n",
      "85:\tlearn: 0.3386592\ttotal: 1m 52s\tremaining: 8m 59s\n",
      "86:\tlearn: 0.3377388\ttotal: 1m 53s\tremaining: 8m 57s\n",
      "87:\tlearn: 0.3368293\ttotal: 1m 54s\tremaining: 8m 56s\n",
      "88:\tlearn: 0.3355321\ttotal: 1m 55s\tremaining: 8m 55s\n",
      "89:\tlearn: 0.3345498\ttotal: 1m 57s\tremaining: 8m 53s\n",
      "90:\tlearn: 0.3337310\ttotal: 1m 58s\tremaining: 8m 52s\n",
      "91:\tlearn: 0.3328336\ttotal: 1m 59s\tremaining: 8m 51s\n",
      "92:\tlearn: 0.3320251\ttotal: 2m 1s\tremaining: 8m 50s\n",
      "93:\tlearn: 0.3309200\ttotal: 2m 2s\tremaining: 8m 48s\n",
      "94:\tlearn: 0.3301071\ttotal: 2m 3s\tremaining: 8m 46s\n",
      "95:\tlearn: 0.3290032\ttotal: 2m 4s\tremaining: 8m 45s\n",
      "96:\tlearn: 0.3281763\ttotal: 2m 6s\tremaining: 8m 43s\n",
      "97:\tlearn: 0.3273253\ttotal: 2m 7s\tremaining: 8m 42s\n",
      "98:\tlearn: 0.3265755\ttotal: 2m 8s\tremaining: 8m 40s\n",
      "99:\tlearn: 0.3254189\ttotal: 2m 9s\tremaining: 8m 39s\n",
      "100:\tlearn: 0.3237869\ttotal: 2m 11s\tremaining: 8m 38s\n",
      "101:\tlearn: 0.3229164\ttotal: 2m 12s\tremaining: 8m 37s\n",
      "102:\tlearn: 0.3220960\ttotal: 2m 13s\tremaining: 8m 35s\n",
      "103:\tlearn: 0.3214446\ttotal: 2m 15s\tremaining: 8m 34s\n",
      "104:\tlearn: 0.3206980\ttotal: 2m 16s\tremaining: 8m 33s\n",
      "105:\tlearn: 0.3200090\ttotal: 2m 17s\tremaining: 8m 31s\n",
      "106:\tlearn: 0.3192220\ttotal: 2m 19s\tremaining: 8m 30s\n",
      "107:\tlearn: 0.3185373\ttotal: 2m 20s\tremaining: 8m 28s\n",
      "108:\tlearn: 0.3177553\ttotal: 2m 21s\tremaining: 8m 27s\n",
      "109:\tlearn: 0.3170028\ttotal: 2m 22s\tremaining: 8m 25s\n",
      "110:\tlearn: 0.3163596\ttotal: 2m 23s\tremaining: 8m 24s\n",
      "111:\tlearn: 0.3157607\ttotal: 2m 25s\tremaining: 8m 23s\n",
      "112:\tlearn: 0.3145418\ttotal: 2m 26s\tremaining: 8m 21s\n",
      "113:\tlearn: 0.3137917\ttotal: 2m 27s\tremaining: 8m 20s\n",
      "114:\tlearn: 0.3130241\ttotal: 2m 28s\tremaining: 8m 18s\n",
      "115:\tlearn: 0.3123863\ttotal: 2m 30s\tremaining: 8m 17s\n",
      "116:\tlearn: 0.3116369\ttotal: 2m 31s\tremaining: 8m 15s\n",
      "117:\tlearn: 0.3110015\ttotal: 2m 32s\tremaining: 8m 13s\n",
      "118:\tlearn: 0.3102464\ttotal: 2m 33s\tremaining: 8m 11s\n",
      "119:\tlearn: 0.3097064\ttotal: 2m 34s\tremaining: 8m 10s\n",
      "120:\tlearn: 0.3088519\ttotal: 2m 35s\tremaining: 8m 8s\n",
      "121:\tlearn: 0.3081980\ttotal: 2m 37s\tremaining: 8m 6s\n",
      "122:\tlearn: 0.3074769\ttotal: 2m 38s\tremaining: 8m 5s\n",
      "123:\tlearn: 0.3068844\ttotal: 2m 39s\tremaining: 8m 3s\n",
      "124:\tlearn: 0.3063826\ttotal: 2m 40s\tremaining: 8m 1s\n",
      "125:\tlearn: 0.3057634\ttotal: 2m 41s\tremaining: 8m\n",
      "126:\tlearn: 0.3048124\ttotal: 2m 42s\tremaining: 7m 58s\n",
      "127:\tlearn: 0.3042771\ttotal: 2m 44s\tremaining: 7m 56s\n",
      "128:\tlearn: 0.3036626\ttotal: 2m 45s\tremaining: 7m 55s\n",
      "129:\tlearn: 0.3031123\ttotal: 2m 46s\tremaining: 7m 53s\n",
      "130:\tlearn: 0.3024942\ttotal: 2m 47s\tremaining: 7m 52s\n",
      "131:\tlearn: 0.3019343\ttotal: 2m 49s\tremaining: 7m 51s\n",
      "132:\tlearn: 0.3010266\ttotal: 2m 50s\tremaining: 7m 50s\n",
      "133:\tlearn: 0.3004657\ttotal: 2m 51s\tremaining: 7m 49s\n",
      "134:\tlearn: 0.2999093\ttotal: 2m 52s\tremaining: 7m 47s\n",
      "135:\tlearn: 0.2993198\ttotal: 2m 54s\tremaining: 7m 46s\n",
      "136:\tlearn: 0.2987144\ttotal: 2m 55s\tremaining: 7m 45s\n",
      "137:\tlearn: 0.2981967\ttotal: 2m 57s\tremaining: 7m 44s\n",
      "138:\tlearn: 0.2975228\ttotal: 2m 58s\tremaining: 7m 43s\n",
      "139:\tlearn: 0.2970288\ttotal: 2m 59s\tremaining: 7m 42s\n",
      "140:\tlearn: 0.2964720\ttotal: 3m 1s\tremaining: 7m 41s\n",
      "141:\tlearn: 0.2957090\ttotal: 3m 2s\tremaining: 7m 40s\n",
      "142:\tlearn: 0.2952131\ttotal: 3m 3s\tremaining: 7m 38s\n",
      "143:\tlearn: 0.2946237\ttotal: 3m 5s\tremaining: 7m 37s\n",
      "144:\tlearn: 0.2940866\ttotal: 3m 6s\tremaining: 7m 36s\n",
      "145:\tlearn: 0.2936227\ttotal: 3m 7s\tremaining: 7m 34s\n",
      "146:\tlearn: 0.2930931\ttotal: 3m 8s\tremaining: 7m 33s\n",
      "147:\tlearn: 0.2925270\ttotal: 3m 10s\tremaining: 7m 32s\n",
      "148:\tlearn: 0.2920127\ttotal: 3m 11s\tremaining: 7m 31s\n",
      "149:\tlearn: 0.2914050\ttotal: 3m 12s\tremaining: 7m 30s\n",
      "150:\tlearn: 0.2905462\ttotal: 3m 14s\tremaining: 7m 28s\n",
      "151:\tlearn: 0.2901995\ttotal: 3m 15s\tremaining: 7m 27s\n",
      "152:\tlearn: 0.2896459\ttotal: 3m 16s\tremaining: 7m 26s\n",
      "153:\tlearn: 0.2889398\ttotal: 3m 17s\tremaining: 7m 24s\n",
      "154:\tlearn: 0.2884419\ttotal: 3m 19s\tremaining: 7m 23s\n",
      "155:\tlearn: 0.2880627\ttotal: 3m 20s\tremaining: 7m 21s\n",
      "156:\tlearn: 0.2876728\ttotal: 3m 21s\tremaining: 7m 20s\n",
      "157:\tlearn: 0.2871803\ttotal: 3m 22s\tremaining: 7m 18s\n",
      "158:\tlearn: 0.2865770\ttotal: 3m 24s\tremaining: 7m 17s\n",
      "159:\tlearn: 0.2855951\ttotal: 3m 25s\tremaining: 7m 16s\n",
      "160:\tlearn: 0.2851962\ttotal: 3m 26s\tremaining: 7m 14s\n",
      "161:\tlearn: 0.2848692\ttotal: 3m 27s\tremaining: 7m 13s\n",
      "162:\tlearn: 0.2845158\ttotal: 3m 29s\tremaining: 7m 12s\n",
      "163:\tlearn: 0.2840802\ttotal: 3m 30s\tremaining: 7m 11s\n",
      "164:\tlearn: 0.2836855\ttotal: 3m 31s\tremaining: 7m 10s\n",
      "165:\tlearn: 0.2830668\ttotal: 3m 33s\tremaining: 7m 8s\n",
      "166:\tlearn: 0.2826630\ttotal: 3m 34s\tremaining: 7m 7s\n",
      "167:\tlearn: 0.2821116\ttotal: 3m 35s\tremaining: 7m 6s\n",
      "168:\tlearn: 0.2813809\ttotal: 3m 36s\tremaining: 7m 4s\n",
      "169:\tlearn: 0.2809381\ttotal: 3m 38s\tremaining: 7m 3s\n",
      "170:\tlearn: 0.2805314\ttotal: 3m 39s\tremaining: 7m 2s\n",
      "171:\tlearn: 0.2800658\ttotal: 3m 41s\tremaining: 7m 2s\n",
      "172:\tlearn: 0.2795901\ttotal: 3m 42s\tremaining: 7m 1s\n",
      "173:\tlearn: 0.2789973\ttotal: 3m 44s\tremaining: 6m 59s\n",
      "174:\tlearn: 0.2785023\ttotal: 3m 45s\tremaining: 6m 58s\n",
      "175:\tlearn: 0.2780705\ttotal: 3m 46s\tremaining: 6m 57s\n",
      "176:\tlearn: 0.2776298\ttotal: 3m 47s\tremaining: 6m 55s\n",
      "177:\tlearn: 0.2772812\ttotal: 3m 49s\tremaining: 6m 54s\n",
      "178:\tlearn: 0.2769196\ttotal: 3m 50s\tremaining: 6m 52s\n",
      "179:\tlearn: 0.2765327\ttotal: 3m 51s\tremaining: 6m 51s\n",
      "180:\tlearn: 0.2761396\ttotal: 3m 52s\tremaining: 6m 49s\n",
      "181:\tlearn: 0.2758295\ttotal: 3m 53s\tremaining: 6m 48s\n",
      "182:\tlearn: 0.2753639\ttotal: 3m 54s\tremaining: 6m 46s\n",
      "183:\tlearn: 0.2748819\ttotal: 3m 56s\tremaining: 6m 45s\n",
      "184:\tlearn: 0.2744049\ttotal: 3m 57s\tremaining: 6m 44s\n",
      "185:\tlearn: 0.2739442\ttotal: 3m 58s\tremaining: 6m 43s\n",
      "186:\tlearn: 0.2735599\ttotal: 3m 59s\tremaining: 6m 41s\n",
      "187:\tlearn: 0.2732421\ttotal: 4m 1s\tremaining: 6m 40s\n",
      "188:\tlearn: 0.2728315\ttotal: 4m 2s\tremaining: 6m 39s\n",
      "189:\tlearn: 0.2725289\ttotal: 4m 4s\tremaining: 6m 38s\n",
      "190:\tlearn: 0.2721385\ttotal: 4m 5s\tremaining: 6m 37s\n",
      "191:\tlearn: 0.2717021\ttotal: 4m 7s\tremaining: 6m 36s\n",
      "192:\tlearn: 0.2712664\ttotal: 4m 8s\tremaining: 6m 34s\n",
      "193:\tlearn: 0.2709697\ttotal: 4m 9s\tremaining: 6m 33s\n",
      "194:\tlearn: 0.2707067\ttotal: 4m 10s\tremaining: 6m 32s\n",
      "195:\tlearn: 0.2703411\ttotal: 4m 12s\tremaining: 6m 30s\n",
      "196:\tlearn: 0.2698687\ttotal: 4m 13s\tremaining: 6m 29s\n",
      "197:\tlearn: 0.2695714\ttotal: 4m 14s\tremaining: 6m 28s\n",
      "198:\tlearn: 0.2691145\ttotal: 4m 15s\tremaining: 6m 26s\n",
      "199:\tlearn: 0.2688021\ttotal: 4m 16s\tremaining: 6m 25s\n",
      "200:\tlearn: 0.2684296\ttotal: 4m 17s\tremaining: 6m 23s\n",
      "201:\tlearn: 0.2680260\ttotal: 4m 19s\tremaining: 6m 22s\n",
      "202:\tlearn: 0.2676034\ttotal: 4m 20s\tremaining: 6m 20s\n",
      "203:\tlearn: 0.2672668\ttotal: 4m 21s\tremaining: 6m 19s\n",
      "204:\tlearn: 0.2669146\ttotal: 4m 22s\tremaining: 6m 18s\n",
      "205:\tlearn: 0.2665347\ttotal: 4m 23s\tremaining: 6m 16s\n",
      "206:\tlearn: 0.2661327\ttotal: 4m 25s\tremaining: 6m 15s\n",
      "207:\tlearn: 0.2658284\ttotal: 4m 26s\tremaining: 6m 13s\n",
      "208:\tlearn: 0.2654888\ttotal: 4m 27s\tremaining: 6m 12s\n",
      "209:\tlearn: 0.2651207\ttotal: 4m 28s\tremaining: 6m 11s\n",
      "210:\tlearn: 0.2645998\ttotal: 4m 30s\tremaining: 6m 9s\n",
      "211:\tlearn: 0.2642857\ttotal: 4m 31s\tremaining: 6m 8s\n",
      "212:\tlearn: 0.2638931\ttotal: 4m 32s\tremaining: 6m 7s\n",
      "213:\tlearn: 0.2635107\ttotal: 4m 33s\tremaining: 6m 5s\n",
      "214:\tlearn: 0.2632227\ttotal: 4m 34s\tremaining: 6m 4s\n",
      "215:\tlearn: 0.2628303\ttotal: 4m 36s\tremaining: 6m 3s\n",
      "216:\tlearn: 0.2625163\ttotal: 4m 37s\tremaining: 6m 2s\n",
      "217:\tlearn: 0.2620862\ttotal: 4m 38s\tremaining: 6m\n",
      "218:\tlearn: 0.2617728\ttotal: 4m 40s\tremaining: 5m 59s\n",
      "219:\tlearn: 0.2615239\ttotal: 4m 41s\tremaining: 5m 58s\n",
      "220:\tlearn: 0.2611769\ttotal: 4m 42s\tremaining: 5m 57s\n",
      "221:\tlearn: 0.2608770\ttotal: 4m 44s\tremaining: 5m 55s\n",
      "222:\tlearn: 0.2606664\ttotal: 4m 45s\tremaining: 5m 54s\n",
      "223:\tlearn: 0.2602671\ttotal: 4m 46s\tremaining: 5m 53s\n",
      "224:\tlearn: 0.2597452\ttotal: 4m 47s\tremaining: 5m 51s\n",
      "225:\tlearn: 0.2594456\ttotal: 4m 49s\tremaining: 5m 50s\n",
      "226:\tlearn: 0.2592160\ttotal: 4m 50s\tremaining: 5m 49s\n",
      "227:\tlearn: 0.2589076\ttotal: 4m 52s\tremaining: 5m 48s\n",
      "228:\tlearn: 0.2585515\ttotal: 4m 53s\tremaining: 5m 47s\n",
      "229:\tlearn: 0.2583596\ttotal: 4m 54s\tremaining: 5m 46s\n",
      "230:\tlearn: 0.2580033\ttotal: 4m 56s\tremaining: 5m 44s\n",
      "231:\tlearn: 0.2577124\ttotal: 4m 57s\tremaining: 5m 43s\n",
      "232:\tlearn: 0.2573507\ttotal: 4m 59s\tremaining: 5m 42s\n",
      "233:\tlearn: 0.2571441\ttotal: 5m\tremaining: 5m 41s\n",
      "234:\tlearn: 0.2567825\ttotal: 5m 1s\tremaining: 5m 40s\n",
      "235:\tlearn: 0.2564333\ttotal: 5m 3s\tremaining: 5m 39s\n",
      "236:\tlearn: 0.2561311\ttotal: 5m 4s\tremaining: 5m 37s\n",
      "237:\tlearn: 0.2556514\ttotal: 5m 5s\tremaining: 5m 36s\n",
      "238:\tlearn: 0.2553705\ttotal: 5m 6s\tremaining: 5m 35s\n",
      "239:\tlearn: 0.2550999\ttotal: 5m 8s\tremaining: 5m 33s\n",
      "240:\tlearn: 0.2547630\ttotal: 5m 9s\tremaining: 5m 32s\n",
      "241:\tlearn: 0.2545740\ttotal: 5m 10s\tremaining: 5m 31s\n",
      "242:\tlearn: 0.2542750\ttotal: 5m 11s\tremaining: 5m 29s\n",
      "243:\tlearn: 0.2539599\ttotal: 5m 13s\tremaining: 5m 28s\n",
      "244:\tlearn: 0.2535825\ttotal: 5m 14s\tremaining: 5m 27s\n",
      "245:\tlearn: 0.2530570\ttotal: 5m 15s\tremaining: 5m 25s\n",
      "246:\tlearn: 0.2527935\ttotal: 5m 16s\tremaining: 5m 24s\n",
      "247:\tlearn: 0.2525458\ttotal: 5m 17s\tremaining: 5m 23s\n",
      "248:\tlearn: 0.2522359\ttotal: 5m 19s\tremaining: 5m 21s\n",
      "249:\tlearn: 0.2519339\ttotal: 5m 20s\tremaining: 5m 20s\n",
      "250:\tlearn: 0.2516304\ttotal: 5m 21s\tremaining: 5m 19s\n",
      "251:\tlearn: 0.2514517\ttotal: 5m 23s\tremaining: 5m 18s\n",
      "252:\tlearn: 0.2512039\ttotal: 5m 24s\tremaining: 5m 16s\n",
      "253:\tlearn: 0.2509187\ttotal: 5m 25s\tremaining: 5m 15s\n",
      "254:\tlearn: 0.2506497\ttotal: 5m 27s\tremaining: 5m 14s\n",
      "255:\tlearn: 0.2502865\ttotal: 5m 29s\tremaining: 5m 13s\n",
      "256:\tlearn: 0.2501041\ttotal: 5m 30s\tremaining: 5m 12s\n",
      "257:\tlearn: 0.2498361\ttotal: 5m 31s\tremaining: 5m 11s\n",
      "258:\tlearn: 0.2494994\ttotal: 5m 33s\tremaining: 5m 9s\n",
      "259:\tlearn: 0.2491096\ttotal: 5m 34s\tremaining: 5m 8s\n",
      "260:\tlearn: 0.2487025\ttotal: 5m 35s\tremaining: 5m 7s\n",
      "261:\tlearn: 0.2485183\ttotal: 5m 37s\tremaining: 5m 6s\n",
      "262:\tlearn: 0.2481998\ttotal: 5m 38s\tremaining: 5m 5s\n",
      "263:\tlearn: 0.2479331\ttotal: 5m 40s\tremaining: 5m 4s\n",
      "264:\tlearn: 0.2476781\ttotal: 5m 41s\tremaining: 5m 3s\n",
      "265:\tlearn: 0.2473519\ttotal: 5m 43s\tremaining: 5m 1s\n",
      "266:\tlearn: 0.2470756\ttotal: 5m 44s\tremaining: 5m\n",
      "267:\tlearn: 0.2468785\ttotal: 5m 45s\tremaining: 4m 58s\n",
      "268:\tlearn: 0.2465947\ttotal: 5m 46s\tremaining: 4m 57s\n",
      "269:\tlearn: 0.2463457\ttotal: 5m 47s\tremaining: 4m 56s\n",
      "270:\tlearn: 0.2459923\ttotal: 5m 49s\tremaining: 4m 54s\n",
      "271:\tlearn: 0.2457745\ttotal: 5m 50s\tremaining: 4m 53s\n",
      "272:\tlearn: 0.2454978\ttotal: 5m 51s\tremaining: 4m 52s\n",
      "273:\tlearn: 0.2453185\ttotal: 5m 52s\tremaining: 4m 51s\n",
      "274:\tlearn: 0.2449692\ttotal: 5m 54s\tremaining: 4m 49s\n",
      "275:\tlearn: 0.2447713\ttotal: 5m 55s\tremaining: 4m 48s\n",
      "276:\tlearn: 0.2443906\ttotal: 5m 57s\tremaining: 4m 47s\n",
      "277:\tlearn: 0.2439924\ttotal: 5m 58s\tremaining: 4m 46s\n",
      "278:\tlearn: 0.2436587\ttotal: 6m\tremaining: 4m 45s\n",
      "279:\tlearn: 0.2432454\ttotal: 6m 2s\tremaining: 4m 44s\n",
      "280:\tlearn: 0.2429755\ttotal: 6m 3s\tremaining: 4m 43s\n",
      "281:\tlearn: 0.2428047\ttotal: 6m 5s\tremaining: 4m 42s\n",
      "282:\tlearn: 0.2426555\ttotal: 6m 6s\tremaining: 4m 41s\n",
      "283:\tlearn: 0.2425062\ttotal: 6m 7s\tremaining: 4m 39s\n",
      "284:\tlearn: 0.2422230\ttotal: 6m 9s\tremaining: 4m 38s\n",
      "285:\tlearn: 0.2420164\ttotal: 6m 10s\tremaining: 4m 37s\n",
      "286:\tlearn: 0.2415745\ttotal: 6m 11s\tremaining: 4m 35s\n",
      "287:\tlearn: 0.2411526\ttotal: 6m 13s\tremaining: 4m 34s\n",
      "288:\tlearn: 0.2406589\ttotal: 6m 14s\tremaining: 4m 33s\n",
      "289:\tlearn: 0.2403339\ttotal: 6m 15s\tremaining: 4m 32s\n",
      "290:\tlearn: 0.2401109\ttotal: 6m 16s\tremaining: 4m 30s\n",
      "291:\tlearn: 0.2398989\ttotal: 6m 18s\tremaining: 4m 29s\n",
      "292:\tlearn: 0.2396428\ttotal: 6m 19s\tremaining: 4m 28s\n",
      "293:\tlearn: 0.2394152\ttotal: 6m 20s\tremaining: 4m 26s\n",
      "294:\tlearn: 0.2390641\ttotal: 6m 22s\tremaining: 4m 25s\n",
      "295:\tlearn: 0.2388800\ttotal: 6m 23s\tremaining: 4m 24s\n",
      "296:\tlearn: 0.2385771\ttotal: 6m 24s\tremaining: 4m 22s\n",
      "297:\tlearn: 0.2382974\ttotal: 6m 26s\tremaining: 4m 21s\n",
      "298:\tlearn: 0.2381686\ttotal: 6m 27s\tremaining: 4m 20s\n",
      "299:\tlearn: 0.2376920\ttotal: 6m 29s\tremaining: 4m 19s\n",
      "300:\tlearn: 0.2373685\ttotal: 6m 30s\tremaining: 4m 18s\n",
      "301:\tlearn: 0.2371191\ttotal: 6m 32s\tremaining: 4m 17s\n",
      "302:\tlearn: 0.2367966\ttotal: 6m 33s\tremaining: 4m 15s\n",
      "303:\tlearn: 0.2365888\ttotal: 6m 34s\tremaining: 4m 14s\n",
      "304:\tlearn: 0.2364311\ttotal: 6m 36s\tremaining: 4m 13s\n",
      "305:\tlearn: 0.2358274\ttotal: 6m 37s\tremaining: 4m 11s\n",
      "306:\tlearn: 0.2355727\ttotal: 6m 38s\tremaining: 4m 10s\n",
      "307:\tlearn: 0.2353460\ttotal: 6m 39s\tremaining: 4m 9s\n",
      "308:\tlearn: 0.2351270\ttotal: 6m 41s\tremaining: 4m 7s\n",
      "309:\tlearn: 0.2348660\ttotal: 6m 42s\tremaining: 4m 6s\n",
      "310:\tlearn: 0.2346377\ttotal: 6m 43s\tremaining: 4m 5s\n",
      "311:\tlearn: 0.2344752\ttotal: 6m 44s\tremaining: 4m 3s\n",
      "312:\tlearn: 0.2341525\ttotal: 6m 45s\tremaining: 4m 2s\n",
      "313:\tlearn: 0.2340254\ttotal: 6m 47s\tremaining: 4m 1s\n",
      "314:\tlearn: 0.2335280\ttotal: 6m 48s\tremaining: 3m 59s\n",
      "315:\tlearn: 0.2332631\ttotal: 6m 49s\tremaining: 3m 58s\n",
      "316:\tlearn: 0.2329874\ttotal: 6m 51s\tremaining: 3m 57s\n",
      "317:\tlearn: 0.2328469\ttotal: 6m 52s\tremaining: 3m 56s\n",
      "318:\tlearn: 0.2325391\ttotal: 6m 54s\tremaining: 3m 54s\n",
      "319:\tlearn: 0.2323205\ttotal: 6m 55s\tremaining: 3m 53s\n",
      "320:\tlearn: 0.2320395\ttotal: 6m 57s\tremaining: 3m 52s\n",
      "321:\tlearn: 0.2318440\ttotal: 6m 58s\tremaining: 3m 51s\n",
      "322:\tlearn: 0.2315946\ttotal: 6m 59s\tremaining: 3m 50s\n",
      "323:\tlearn: 0.2313181\ttotal: 7m 1s\tremaining: 3m 48s\n",
      "324:\tlearn: 0.2311952\ttotal: 7m 2s\tremaining: 3m 47s\n",
      "325:\tlearn: 0.2310385\ttotal: 7m 3s\tremaining: 3m 46s\n",
      "326:\tlearn: 0.2307699\ttotal: 7m 4s\tremaining: 3m 44s\n",
      "327:\tlearn: 0.2305284\ttotal: 7m 6s\tremaining: 3m 43s\n",
      "328:\tlearn: 0.2302667\ttotal: 7m 7s\tremaining: 3m 42s\n",
      "329:\tlearn: 0.2300451\ttotal: 7m 8s\tremaining: 3m 40s\n",
      "330:\tlearn: 0.2297597\ttotal: 7m 9s\tremaining: 3m 39s\n",
      "331:\tlearn: 0.2295621\ttotal: 7m 11s\tremaining: 3m 38s\n",
      "332:\tlearn: 0.2293371\ttotal: 7m 12s\tremaining: 3m 36s\n",
      "333:\tlearn: 0.2291871\ttotal: 7m 13s\tremaining: 3m 35s\n",
      "334:\tlearn: 0.2290323\ttotal: 7m 14s\tremaining: 3m 34s\n",
      "335:\tlearn: 0.2289162\ttotal: 7m 15s\tremaining: 3m 32s\n",
      "336:\tlearn: 0.2287772\ttotal: 7m 17s\tremaining: 3m 31s\n",
      "337:\tlearn: 0.2285553\ttotal: 7m 18s\tremaining: 3m 30s\n",
      "338:\tlearn: 0.2283424\ttotal: 7m 19s\tremaining: 3m 28s\n",
      "339:\tlearn: 0.2281368\ttotal: 7m 20s\tremaining: 3m 27s\n",
      "340:\tlearn: 0.2279240\ttotal: 7m 21s\tremaining: 3m 26s\n",
      "341:\tlearn: 0.2277526\ttotal: 7m 23s\tremaining: 3m 24s\n",
      "342:\tlearn: 0.2275139\ttotal: 7m 24s\tremaining: 3m 23s\n",
      "343:\tlearn: 0.2272810\ttotal: 7m 25s\tremaining: 3m 22s\n",
      "344:\tlearn: 0.2271694\ttotal: 7m 26s\tremaining: 3m 20s\n",
      "345:\tlearn: 0.2269556\ttotal: 7m 28s\tremaining: 3m 19s\n",
      "346:\tlearn: 0.2268152\ttotal: 7m 29s\tremaining: 3m 18s\n",
      "347:\tlearn: 0.2265626\ttotal: 7m 30s\tremaining: 3m 16s\n",
      "348:\tlearn: 0.2263403\ttotal: 7m 32s\tremaining: 3m 15s\n",
      "349:\tlearn: 0.2261161\ttotal: 7m 33s\tremaining: 3m 14s\n",
      "350:\tlearn: 0.2258698\ttotal: 7m 35s\tremaining: 3m 13s\n",
      "351:\tlearn: 0.2256704\ttotal: 7m 36s\tremaining: 3m 12s\n",
      "352:\tlearn: 0.2254924\ttotal: 7m 38s\tremaining: 3m 10s\n",
      "353:\tlearn: 0.2250833\ttotal: 7m 39s\tremaining: 3m 9s\n",
      "354:\tlearn: 0.2248638\ttotal: 7m 41s\tremaining: 3m 8s\n",
      "355:\tlearn: 0.2247471\ttotal: 7m 43s\tremaining: 3m 7s\n",
      "356:\tlearn: 0.2245665\ttotal: 7m 44s\tremaining: 3m 6s\n",
      "357:\tlearn: 0.2244592\ttotal: 7m 45s\tremaining: 3m 4s\n",
      "358:\tlearn: 0.2243316\ttotal: 7m 46s\tremaining: 3m 3s\n",
      "359:\tlearn: 0.2240554\ttotal: 7m 48s\tremaining: 3m 2s\n",
      "360:\tlearn: 0.2238996\ttotal: 7m 49s\tremaining: 3m\n",
      "361:\tlearn: 0.2236373\ttotal: 7m 50s\tremaining: 2m 59s\n",
      "362:\tlearn: 0.2234715\ttotal: 7m 51s\tremaining: 2m 58s\n",
      "363:\tlearn: 0.2232437\ttotal: 7m 53s\tremaining: 2m 56s\n",
      "364:\tlearn: 0.2230321\ttotal: 7m 54s\tremaining: 2m 55s\n",
      "365:\tlearn: 0.2227732\ttotal: 7m 55s\tremaining: 2m 54s\n",
      "366:\tlearn: 0.2226718\ttotal: 7m 57s\tremaining: 2m 52s\n",
      "367:\tlearn: 0.2223831\ttotal: 7m 58s\tremaining: 2m 51s\n",
      "368:\tlearn: 0.2220236\ttotal: 7m 59s\tremaining: 2m 50s\n",
      "369:\tlearn: 0.2218323\ttotal: 8m 1s\tremaining: 2m 49s\n",
      "370:\tlearn: 0.2216290\ttotal: 8m 2s\tremaining: 2m 47s\n",
      "371:\tlearn: 0.2214289\ttotal: 8m 3s\tremaining: 2m 46s\n",
      "372:\tlearn: 0.2212336\ttotal: 8m 4s\tremaining: 2m 45s\n",
      "373:\tlearn: 0.2211084\ttotal: 8m 5s\tremaining: 2m 43s\n",
      "374:\tlearn: 0.2210120\ttotal: 8m 7s\tremaining: 2m 42s\n",
      "375:\tlearn: 0.2207045\ttotal: 8m 8s\tremaining: 2m 41s\n",
      "376:\tlearn: 0.2204305\ttotal: 8m 9s\tremaining: 2m 39s\n",
      "377:\tlearn: 0.2202382\ttotal: 8m 10s\tremaining: 2m 38s\n",
      "378:\tlearn: 0.2200059\ttotal: 8m 11s\tremaining: 2m 37s\n",
      "379:\tlearn: 0.2196958\ttotal: 8m 13s\tremaining: 2m 35s\n",
      "380:\tlearn: 0.2195037\ttotal: 8m 14s\tremaining: 2m 34s\n",
      "381:\tlearn: 0.2193260\ttotal: 8m 15s\tremaining: 2m 33s\n",
      "382:\tlearn: 0.2192103\ttotal: 8m 16s\tremaining: 2m 31s\n",
      "383:\tlearn: 0.2189733\ttotal: 8m 18s\tremaining: 2m 30s\n",
      "384:\tlearn: 0.2187565\ttotal: 8m 19s\tremaining: 2m 29s\n",
      "385:\tlearn: 0.2185275\ttotal: 8m 20s\tremaining: 2m 27s\n",
      "386:\tlearn: 0.2178191\ttotal: 8m 22s\tremaining: 2m 26s\n",
      "387:\tlearn: 0.2177216\ttotal: 8m 23s\tremaining: 2m 25s\n",
      "388:\tlearn: 0.2174990\ttotal: 8m 24s\tremaining: 2m 23s\n",
      "389:\tlearn: 0.2172856\ttotal: 8m 25s\tremaining: 2m 22s\n",
      "390:\tlearn: 0.2171721\ttotal: 8m 27s\tremaining: 2m 21s\n",
      "391:\tlearn: 0.2169293\ttotal: 8m 28s\tremaining: 2m 20s\n",
      "392:\tlearn: 0.2168324\ttotal: 8m 30s\tremaining: 2m 18s\n",
      "393:\tlearn: 0.2166070\ttotal: 8m 31s\tremaining: 2m 17s\n",
      "394:\tlearn: 0.2164495\ttotal: 8m 32s\tremaining: 2m 16s\n",
      "395:\tlearn: 0.2163356\ttotal: 8m 34s\tremaining: 2m 14s\n",
      "396:\tlearn: 0.2161148\ttotal: 8m 35s\tremaining: 2m 13s\n",
      "397:\tlearn: 0.2160215\ttotal: 8m 36s\tremaining: 2m 12s\n",
      "398:\tlearn: 0.2157816\ttotal: 8m 37s\tremaining: 2m 11s\n",
      "399:\tlearn: 0.2155731\ttotal: 8m 39s\tremaining: 2m 9s\n",
      "400:\tlearn: 0.2153212\ttotal: 8m 40s\tremaining: 2m 8s\n",
      "401:\tlearn: 0.2151408\ttotal: 8m 41s\tremaining: 2m 7s\n",
      "402:\tlearn: 0.2150291\ttotal: 8m 42s\tremaining: 2m 5s\n",
      "403:\tlearn: 0.2147695\ttotal: 8m 44s\tremaining: 2m 4s\n",
      "404:\tlearn: 0.2146071\ttotal: 8m 45s\tremaining: 2m 3s\n",
      "405:\tlearn: 0.2144100\ttotal: 8m 46s\tremaining: 2m 1s\n",
      "406:\tlearn: 0.2142655\ttotal: 8m 47s\tremaining: 2m\n",
      "407:\tlearn: 0.2140539\ttotal: 8m 49s\tremaining: 1m 59s\n",
      "408:\tlearn: 0.2139071\ttotal: 8m 50s\tremaining: 1m 58s\n",
      "409:\tlearn: 0.2136766\ttotal: 8m 51s\tremaining: 1m 56s\n",
      "410:\tlearn: 0.2135049\ttotal: 8m 53s\tremaining: 1m 55s\n",
      "411:\tlearn: 0.2134143\ttotal: 8m 54s\tremaining: 1m 54s\n",
      "412:\tlearn: 0.2133020\ttotal: 8m 55s\tremaining: 1m 52s\n",
      "413:\tlearn: 0.2131097\ttotal: 8m 57s\tremaining: 1m 51s\n",
      "414:\tlearn: 0.2128692\ttotal: 8m 58s\tremaining: 1m 50s\n",
      "415:\tlearn: 0.2127090\ttotal: 8m 59s\tremaining: 1m 49s\n",
      "416:\tlearn: 0.2125032\ttotal: 9m 1s\tremaining: 1m 47s\n",
      "417:\tlearn: 0.2124123\ttotal: 9m 2s\tremaining: 1m 46s\n",
      "418:\tlearn: 0.2122978\ttotal: 9m 3s\tremaining: 1m 45s\n",
      "419:\tlearn: 0.2120935\ttotal: 9m 5s\tremaining: 1m 43s\n",
      "420:\tlearn: 0.2119271\ttotal: 9m 6s\tremaining: 1m 42s\n",
      "421:\tlearn: 0.2117620\ttotal: 9m 7s\tremaining: 1m 41s\n",
      "422:\tlearn: 0.2115708\ttotal: 9m 8s\tremaining: 1m 39s\n",
      "423:\tlearn: 0.2114809\ttotal: 9m 9s\tremaining: 1m 38s\n",
      "424:\tlearn: 0.2113941\ttotal: 9m 11s\tremaining: 1m 37s\n",
      "425:\tlearn: 0.2113093\ttotal: 9m 12s\tremaining: 1m 35s\n",
      "426:\tlearn: 0.2111125\ttotal: 9m 13s\tremaining: 1m 34s\n",
      "427:\tlearn: 0.2107597\ttotal: 9m 15s\tremaining: 1m 33s\n",
      "428:\tlearn: 0.2105740\ttotal: 9m 16s\tremaining: 1m 32s\n",
      "429:\tlearn: 0.2103649\ttotal: 9m 18s\tremaining: 1m 30s\n",
      "430:\tlearn: 0.2101628\ttotal: 9m 19s\tremaining: 1m 29s\n",
      "431:\tlearn: 0.2100563\ttotal: 9m 21s\tremaining: 1m 28s\n",
      "432:\tlearn: 0.2098214\ttotal: 9m 22s\tremaining: 1m 27s\n",
      "433:\tlearn: 0.2097346\ttotal: 9m 23s\tremaining: 1m 25s\n",
      "434:\tlearn: 0.2095700\ttotal: 9m 25s\tremaining: 1m 24s\n",
      "435:\tlearn: 0.2094545\ttotal: 9m 26s\tremaining: 1m 23s\n",
      "436:\tlearn: 0.2092557\ttotal: 9m 27s\tremaining: 1m 21s\n",
      "437:\tlearn: 0.2091309\ttotal: 9m 29s\tremaining: 1m 20s\n",
      "438:\tlearn: 0.2089190\ttotal: 9m 30s\tremaining: 1m 19s\n",
      "439:\tlearn: 0.2087148\ttotal: 9m 31s\tremaining: 1m 17s\n",
      "440:\tlearn: 0.2084715\ttotal: 9m 32s\tremaining: 1m 16s\n",
      "441:\tlearn: 0.2082649\ttotal: 9m 34s\tremaining: 1m 15s\n",
      "442:\tlearn: 0.2081036\ttotal: 9m 35s\tremaining: 1m 14s\n",
      "443:\tlearn: 0.2080185\ttotal: 9m 36s\tremaining: 1m 12s\n",
      "444:\tlearn: 0.2077668\ttotal: 9m 38s\tremaining: 1m 11s\n",
      "445:\tlearn: 0.2075739\ttotal: 9m 39s\tremaining: 1m 10s\n",
      "446:\tlearn: 0.2073793\ttotal: 9m 40s\tremaining: 1m 8s\n",
      "447:\tlearn: 0.2072965\ttotal: 9m 41s\tremaining: 1m 7s\n",
      "448:\tlearn: 0.2069903\ttotal: 9m 43s\tremaining: 1m 6s\n",
      "449:\tlearn: 0.2067534\ttotal: 9m 44s\tremaining: 1m 4s\n",
      "450:\tlearn: 0.2066695\ttotal: 9m 45s\tremaining: 1m 3s\n",
      "451:\tlearn: 0.2064694\ttotal: 9m 47s\tremaining: 1m 2s\n",
      "452:\tlearn: 0.2062446\ttotal: 9m 48s\tremaining: 1m 1s\n",
      "453:\tlearn: 0.2060684\ttotal: 9m 49s\tremaining: 59.8s\n",
      "454:\tlearn: 0.2059627\ttotal: 9m 51s\tremaining: 58.5s\n",
      "455:\tlearn: 0.2058800\ttotal: 9m 52s\tremaining: 57.2s\n",
      "456:\tlearn: 0.2057261\ttotal: 9m 53s\tremaining: 55.9s\n",
      "457:\tlearn: 0.2055174\ttotal: 9m 55s\tremaining: 54.6s\n",
      "458:\tlearn: 0.2054118\ttotal: 9m 56s\tremaining: 53.3s\n",
      "459:\tlearn: 0.2052272\ttotal: 9m 58s\tremaining: 52s\n",
      "460:\tlearn: 0.2051451\ttotal: 9m 59s\tremaining: 50.7s\n",
      "461:\tlearn: 0.2050636\ttotal: 10m\tremaining: 49.4s\n",
      "462:\tlearn: 0.2048746\ttotal: 10m 2s\tremaining: 48.1s\n",
      "463:\tlearn: 0.2047463\ttotal: 10m 3s\tremaining: 46.8s\n",
      "464:\tlearn: 0.2045231\ttotal: 10m 4s\tremaining: 45.5s\n",
      "465:\tlearn: 0.2044433\ttotal: 10m 6s\tremaining: 44.2s\n",
      "466:\tlearn: 0.2042397\ttotal: 10m 7s\tremaining: 42.9s\n",
      "467:\tlearn: 0.2040543\ttotal: 10m 8s\tremaining: 41.6s\n",
      "468:\tlearn: 0.2039761\ttotal: 10m 9s\tremaining: 40.3s\n",
      "469:\tlearn: 0.2038191\ttotal: 10m 11s\tremaining: 39s\n",
      "470:\tlearn: 0.2036665\ttotal: 10m 12s\tremaining: 37.7s\n",
      "471:\tlearn: 0.2035654\ttotal: 10m 13s\tremaining: 36.4s\n",
      "472:\tlearn: 0.2033643\ttotal: 10m 14s\tremaining: 35.1s\n",
      "473:\tlearn: 0.2031887\ttotal: 10m 16s\tremaining: 33.8s\n",
      "474:\tlearn: 0.2029668\ttotal: 10m 17s\tremaining: 32.5s\n",
      "475:\tlearn: 0.2028784\ttotal: 10m 18s\tremaining: 31.2s\n",
      "476:\tlearn: 0.2027990\ttotal: 10m 19s\tremaining: 29.9s\n",
      "477:\tlearn: 0.2026116\ttotal: 10m 21s\tremaining: 28.6s\n",
      "478:\tlearn: 0.2025317\ttotal: 10m 22s\tremaining: 27.3s\n",
      "479:\tlearn: 0.2024539\ttotal: 10m 23s\tremaining: 26s\n",
      "480:\tlearn: 0.2023152\ttotal: 10m 25s\tremaining: 24.7s\n",
      "481:\tlearn: 0.2021708\ttotal: 10m 26s\tremaining: 23.4s\n",
      "482:\tlearn: 0.2019890\ttotal: 10m 27s\tremaining: 22.1s\n",
      "483:\tlearn: 0.2019130\ttotal: 10m 29s\tremaining: 20.8s\n",
      "484:\tlearn: 0.2017184\ttotal: 10m 31s\tremaining: 19.5s\n",
      "485:\tlearn: 0.2015545\ttotal: 10m 33s\tremaining: 18.2s\n",
      "486:\tlearn: 0.2014769\ttotal: 10m 37s\tremaining: 17s\n",
      "487:\tlearn: 0.2012857\ttotal: 10m 39s\tremaining: 15.7s\n",
      "488:\tlearn: 0.2010576\ttotal: 10m 43s\tremaining: 14.5s\n",
      "489:\tlearn: 0.2008247\ttotal: 10m 46s\tremaining: 13.2s\n",
      "490:\tlearn: 0.2006613\ttotal: 10m 47s\tremaining: 11.9s\n",
      "491:\tlearn: 0.2005058\ttotal: 10m 49s\tremaining: 10.6s\n",
      "492:\tlearn: 0.2003553\ttotal: 10m 50s\tremaining: 9.24s\n",
      "493:\tlearn: 0.2001426\ttotal: 10m 52s\tremaining: 7.92s\n",
      "494:\tlearn: 0.2000657\ttotal: 10m 53s\tremaining: 6.6s\n",
      "495:\tlearn: 0.1999084\ttotal: 10m 54s\tremaining: 5.28s\n",
      "496:\tlearn: 0.1997017\ttotal: 10m 56s\tremaining: 3.96s\n",
      "497:\tlearn: 0.1994883\ttotal: 10m 58s\tremaining: 2.64s\n",
      "498:\tlearn: 0.1994128\ttotal: 10m 59s\tremaining: 1.32s\n",
      "499:\tlearn: 0.1993367\ttotal: 11m 1s\tremaining: 0us\n",
      "Wall time: 11min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f7ca261e08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "CatBoost_clf.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.750\n",
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(CatBoost_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Обучим модель градиентного бустинга  LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=17, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_params = {'n_estimators': [500],\n",
    "                   'learning_rate': [0.1, 0.3, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                      class_weight='balanced',\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=17, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.3, 0.5],\n",
       "                         'n_estimators': [500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_clf_grid = GridSearchCV(lgbm_clf, lgbm_clf_params, scoring='f1')\n",
    "lgbm_clf_grid.fit(train_tf_idf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "best scores:  0.7531108305028578\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', lgbm_clf_grid.best_params_)\n",
    "print('best scores: ', lgbm_clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=17, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.762\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring(lgbm_clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с загрузки необходимых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import notebook\n",
    "import torch\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT представляет собой уменьшенную версию BERT'а. Она быстрее и легче своего старшего собрата, но при этом вполне сравнима в результативности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предобученную модель DistilBERT и токенизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       explanation why the edits make under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not try to edit war it s ju...  \n",
       "3       more i can t make any real suggestion on impro...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of ask when your view ...  \n",
       "159567  you should be ashamed of yourself that be a ho...  \n",
       "159568  spitzer umm there no actual article for prosti...  \n",
       "159569  and it look like it be actually you who put on...  \n",
       "159570  and i really don t think you understand i come...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенезацию исходных текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=df['text'].shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель DistilBERT принимает максимальное количество токенов в тексте по умолчанию равное 512. Посчитаем длины текстов с токенами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sentences = [len(i) for i in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean         94.891860\n",
       "std         141.438775\n",
       "min           4.000000\n",
       "25%          26.000000\n",
       "50%          52.000000\n",
       "75%         104.000000\n",
       "max        4950.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sentences = pd.Series(len_sentences)\n",
    "len_sentences.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видем что есть аномально длинные. Ограничим тексты максимальной длиной токенов 75% квантилем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f1ac8c09f54ec2ae61ea767c697197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=159571), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "for i in notebook.tqdm(range(len(tokenized))):\n",
    "    if len(tokenized[i]) <= len_sentences.quantile(.75):\n",
    "        indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119975"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные индексы \"коротких\" текстов применим к Датафрейму:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.query('index in @indexes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размеры ДатаФрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119975, 3)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на 2 части: обучающую и тестовую выбороки в пропорциях по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_train, filtered_df_test = train_test_split(filtered_df, random_state=17, test_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114975, 3), (5000, 3))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_train.shape, filtered_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы сбалансировать метки целевого признака в обучающей выборке, воспользуемся техникой **downsampling** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки downsampling  \n",
    "- Разделим обучающую выборку на отрицательные и положительные объекты\n",
    "- Случайным образом отбросим часть из отрицательных объектов;\n",
    "- С учётом полученных данных создадим новую обучающую выборку;\n",
    "- Перемешаем данные. Положительные не должны идти следом за отрицательными: алгоритмам будет сложнее обучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотри на отнощение класса \"1\" к \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.127"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef  = round((len(filtered_df_train[filtered_df_train['toxic'] == 1]) / \n",
    "               len(filtered_df_train[filtered_df_train['toxic'] == 0])), 3)\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию **downsample(features, target, fraction)** для формирования сблалансированной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=17)] +\n",
    "                                     [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=17)] +\n",
    "                                     [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled,\n",
    "                                                      random_state=17)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(filtered_df_train['text'], filtered_df_train['toxic'], coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры получившихся выборок и распределение целевого признака в обучающей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25946,), (25946,))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_downsampled.shape, target_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "sns.countplot(target_downsampled, palette='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объеденим снова в один ДатаФрейм обучающую выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled = pd.DataFrame(features_downsampled).reset_index(drop=True)\n",
    "target_downsampled = pd.DataFrame(target_downsampled).reset_index(drop=True)\n",
    "filtered_df_train = features_downsampled.join(target_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25946, 2), (5000, 3))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_train.shape, filtered_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эмбеддинги модель BERT создаёт батчами. Чтобы хватило оперативной памяти, сделаем размер батча небольшим (100). Обучающую выборку сделаем кратной размеру батча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_train = filtered_df_train[:25900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенезацию новых текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_train = filtered_df_train['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=filtered_df_train['text'].shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_test = filtered_df_test['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=filtered_df_test['text'].shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными. Только при таком условии будет работать модель BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(tokenized):\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    return padded\n",
    "\n",
    "padded_train = padding(tokenized_train)\n",
    "padded_test = padding(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25900, 104), (5000, 104))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded_train).shape, np.array(padded_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поясним модели, что нули не несут значимой информации. Это нужно для компоненты модели, которая называется «внимание». Отбросим эти токены и «создадим маску» для действительно важных токенов, то есть укажем нулевые и не нулевые значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25900, 104), (5000, 104))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_train = np.where(padded_train != 0, 1, 0)\n",
    "attention_mask_test = np.where(padded_test != 0, 1, 0)\n",
    "attention_mask_train.shape, attention_mask_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем цикл по батчам. Отображать прогресс будет функция notebook()  \n",
    "Преобразуем данные в формат тензоров  — многомерных векторов в библиотеке torch. Тип данных LongTensor хранит числа в «длинном формате», то есть выделяет на каждое число 64 бита.  \n",
    "Чтобы получить эмбеддинги для батча, передадим модели данные и маску  \n",
    "Для ускорения вычисления функцией no_grad() в библиотеке torch укажем, что градиенты не нужны: модель BERT обучать не будем.  \n",
    "Из полученного тензора извлечём нужные элементы `batch_embeddings[0][:,0,:].numpy()` и добавим в список всех эмбеддингов  \n",
    "Соберём все эмбеддинги в матрицу признаков вызовов функции `concatenate()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedings(padded, attention_mask):\n",
    "    batch_size = 100\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "            batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    features = np.concatenate(embeddings)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80183a38bd474470bc239f7e2340e4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_train = embedings(padded_train, attention_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032a58bc21104ae68bf3f9a0d4b3af8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_test = embedings(padded_test, attention_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевые признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = filtered_df_train['toxic']\n",
    "labels_test = filtered_df_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_BERT(fitted_model):\n",
    "    test_pred = fitted_model.predict(features_test)\n",
    "    test_f1 = f1_score(labels_test, test_pred)\n",
    "    \n",
    "    print('F1 на тестовой выборке: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Обучим Логистическую регрессию LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {'C': np.linspace(0.0001, 100, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=17, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000e-04, 1.11112e+01, 2.22223e+01, 3.33334e+01, 4.44445e+01,\n",
       "       5.55556e+01, 6.66667e+01, 7.77778e+01, 8.88889e+01, 1.00000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_grid = GridSearchCV(log_reg, log_reg_params, scoring='f1')\n",
    "log_reg_grid.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 11.1112}\n",
      "best scores:  0.8982250490907951\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', log_reg_grid.best_params_)\n",
    "print('best scores: ', log_reg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=11.1112, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=17, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.690\n",
      "Wall time: 28.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring_BERT(log_reg_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучим модель градиентного бустинга  XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=17, n_jobs=-1, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=17, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.676\n"
     ]
    }
   ],
   "source": [
    "scoring_BERT(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Обучим модель градиентного бустинга  CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoost_clf = CatBoostClassifier(random_state=17, iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.078065\n",
      "0:\tlearn: 0.6415097\ttotal: 262ms\tremaining: 2m 10s\n",
      "1:\tlearn: 0.5955524\ttotal: 485ms\tremaining: 2m\n",
      "2:\tlearn: 0.5568050\ttotal: 707ms\tremaining: 1m 57s\n",
      "3:\tlearn: 0.5256337\ttotal: 932ms\tremaining: 1m 55s\n",
      "4:\tlearn: 0.4973114\ttotal: 1.16s\tremaining: 1m 55s\n",
      "5:\tlearn: 0.4739741\ttotal: 1.39s\tremaining: 1m 54s\n",
      "6:\tlearn: 0.4553641\ttotal: 1.61s\tremaining: 1m 53s\n",
      "7:\tlearn: 0.4395781\ttotal: 1.84s\tremaining: 1m 53s\n",
      "8:\tlearn: 0.4262589\ttotal: 2.06s\tremaining: 1m 52s\n",
      "9:\tlearn: 0.4137069\ttotal: 2.29s\tremaining: 1m 52s\n",
      "10:\tlearn: 0.4025736\ttotal: 2.52s\tremaining: 1m 51s\n",
      "11:\tlearn: 0.3922578\ttotal: 2.74s\tremaining: 1m 51s\n",
      "12:\tlearn: 0.3836808\ttotal: 2.97s\tremaining: 1m 51s\n",
      "13:\tlearn: 0.3760168\ttotal: 3.19s\tremaining: 1m 50s\n",
      "14:\tlearn: 0.3684765\ttotal: 3.42s\tremaining: 1m 50s\n",
      "15:\tlearn: 0.3619674\ttotal: 3.65s\tremaining: 1m 50s\n",
      "16:\tlearn: 0.3563597\ttotal: 3.87s\tremaining: 1m 50s\n",
      "17:\tlearn: 0.3514805\ttotal: 4.09s\tremaining: 1m 49s\n",
      "18:\tlearn: 0.3464721\ttotal: 4.32s\tremaining: 1m 49s\n",
      "19:\tlearn: 0.3423971\ttotal: 4.54s\tremaining: 1m 49s\n",
      "20:\tlearn: 0.3379830\ttotal: 4.77s\tremaining: 1m 48s\n",
      "21:\tlearn: 0.3340703\ttotal: 5.02s\tremaining: 1m 49s\n",
      "22:\tlearn: 0.3311129\ttotal: 5.23s\tremaining: 1m 48s\n",
      "23:\tlearn: 0.3281256\ttotal: 5.43s\tremaining: 1m 47s\n",
      "24:\tlearn: 0.3250589\ttotal: 5.65s\tremaining: 1m 47s\n",
      "25:\tlearn: 0.3220159\ttotal: 5.85s\tremaining: 1m 46s\n",
      "26:\tlearn: 0.3194388\ttotal: 6.05s\tremaining: 1m 46s\n",
      "27:\tlearn: 0.3170567\ttotal: 6.25s\tremaining: 1m 45s\n",
      "28:\tlearn: 0.3146477\ttotal: 6.46s\tremaining: 1m 44s\n",
      "29:\tlearn: 0.3120660\ttotal: 6.66s\tremaining: 1m 44s\n",
      "30:\tlearn: 0.3100556\ttotal: 6.86s\tremaining: 1m 43s\n",
      "31:\tlearn: 0.3080396\ttotal: 7.07s\tremaining: 1m 43s\n",
      "32:\tlearn: 0.3064350\ttotal: 7.26s\tremaining: 1m 42s\n",
      "33:\tlearn: 0.3046068\ttotal: 7.46s\tremaining: 1m 42s\n",
      "34:\tlearn: 0.3029210\ttotal: 7.67s\tremaining: 1m 41s\n",
      "35:\tlearn: 0.3012239\ttotal: 7.87s\tremaining: 1m 41s\n",
      "36:\tlearn: 0.2994776\ttotal: 8.06s\tremaining: 1m 40s\n",
      "37:\tlearn: 0.2981487\ttotal: 8.26s\tremaining: 1m 40s\n",
      "38:\tlearn: 0.2967282\ttotal: 8.46s\tremaining: 1m 40s\n",
      "39:\tlearn: 0.2952042\ttotal: 8.67s\tremaining: 1m 39s\n",
      "40:\tlearn: 0.2935965\ttotal: 8.87s\tremaining: 1m 39s\n",
      "41:\tlearn: 0.2922474\ttotal: 9.07s\tremaining: 1m 38s\n",
      "42:\tlearn: 0.2906220\ttotal: 9.27s\tremaining: 1m 38s\n",
      "43:\tlearn: 0.2893709\ttotal: 9.48s\tremaining: 1m 38s\n",
      "44:\tlearn: 0.2882390\ttotal: 9.68s\tremaining: 1m 37s\n",
      "45:\tlearn: 0.2872310\ttotal: 9.88s\tremaining: 1m 37s\n",
      "46:\tlearn: 0.2862711\ttotal: 10.1s\tremaining: 1m 37s\n",
      "47:\tlearn: 0.2850370\ttotal: 10.3s\tremaining: 1m 36s\n",
      "48:\tlearn: 0.2839803\ttotal: 10.5s\tremaining: 1m 36s\n",
      "49:\tlearn: 0.2829457\ttotal: 10.7s\tremaining: 1m 36s\n",
      "50:\tlearn: 0.2819379\ttotal: 10.9s\tremaining: 1m 35s\n",
      "51:\tlearn: 0.2807677\ttotal: 11.1s\tremaining: 1m 35s\n",
      "52:\tlearn: 0.2796710\ttotal: 11.3s\tremaining: 1m 35s\n",
      "53:\tlearn: 0.2786789\ttotal: 11.5s\tremaining: 1m 34s\n",
      "54:\tlearn: 0.2776886\ttotal: 11.7s\tremaining: 1m 34s\n",
      "55:\tlearn: 0.2767028\ttotal: 11.9s\tremaining: 1m 34s\n",
      "56:\tlearn: 0.2759411\ttotal: 12.1s\tremaining: 1m 33s\n",
      "57:\tlearn: 0.2752159\ttotal: 12.3s\tremaining: 1m 33s\n",
      "58:\tlearn: 0.2744998\ttotal: 12.5s\tremaining: 1m 33s\n",
      "59:\tlearn: 0.2735411\ttotal: 12.7s\tremaining: 1m 32s\n",
      "60:\tlearn: 0.2725316\ttotal: 12.9s\tremaining: 1m 32s\n",
      "61:\tlearn: 0.2717453\ttotal: 13.1s\tremaining: 1m 32s\n",
      "62:\tlearn: 0.2710379\ttotal: 13.3s\tremaining: 1m 32s\n",
      "63:\tlearn: 0.2701955\ttotal: 13.5s\tremaining: 1m 31s\n",
      "64:\tlearn: 0.2694923\ttotal: 13.7s\tremaining: 1m 31s\n",
      "65:\tlearn: 0.2685432\ttotal: 13.9s\tremaining: 1m 31s\n",
      "66:\tlearn: 0.2676812\ttotal: 14.1s\tremaining: 1m 31s\n",
      "67:\tlearn: 0.2670838\ttotal: 14.3s\tremaining: 1m 30s\n",
      "68:\tlearn: 0.2662606\ttotal: 14.5s\tremaining: 1m 30s\n",
      "69:\tlearn: 0.2656722\ttotal: 14.7s\tremaining: 1m 30s\n",
      "70:\tlearn: 0.2649998\ttotal: 14.9s\tremaining: 1m 29s\n",
      "71:\tlearn: 0.2643462\ttotal: 15.1s\tremaining: 1m 29s\n",
      "72:\tlearn: 0.2636798\ttotal: 15.3s\tremaining: 1m 29s\n",
      "73:\tlearn: 0.2629066\ttotal: 15.5s\tremaining: 1m 29s\n",
      "74:\tlearn: 0.2621928\ttotal: 15.7s\tremaining: 1m 28s\n",
      "75:\tlearn: 0.2615529\ttotal: 15.9s\tremaining: 1m 28s\n",
      "76:\tlearn: 0.2607918\ttotal: 16.1s\tremaining: 1m 28s\n",
      "77:\tlearn: 0.2602366\ttotal: 16.3s\tremaining: 1m 28s\n",
      "78:\tlearn: 0.2596166\ttotal: 16.5s\tremaining: 1m 27s\n",
      "79:\tlearn: 0.2590466\ttotal: 16.7s\tremaining: 1m 27s\n",
      "80:\tlearn: 0.2583594\ttotal: 16.9s\tremaining: 1m 27s\n",
      "81:\tlearn: 0.2577744\ttotal: 17.1s\tremaining: 1m 26s\n",
      "82:\tlearn: 0.2572540\ttotal: 17.3s\tremaining: 1m 26s\n",
      "83:\tlearn: 0.2566272\ttotal: 17.5s\tremaining: 1m 26s\n",
      "84:\tlearn: 0.2560488\ttotal: 17.7s\tremaining: 1m 26s\n",
      "85:\tlearn: 0.2555903\ttotal: 17.9s\tremaining: 1m 25s\n",
      "86:\tlearn: 0.2551688\ttotal: 18.1s\tremaining: 1m 25s\n",
      "87:\tlearn: 0.2545593\ttotal: 18.3s\tremaining: 1m 25s\n",
      "88:\tlearn: 0.2539204\ttotal: 18.5s\tremaining: 1m 25s\n",
      "89:\tlearn: 0.2533182\ttotal: 18.7s\tremaining: 1m 25s\n",
      "90:\tlearn: 0.2527610\ttotal: 18.9s\tremaining: 1m 25s\n",
      "91:\tlearn: 0.2523561\ttotal: 19.2s\tremaining: 1m 24s\n",
      "92:\tlearn: 0.2519003\ttotal: 19.4s\tremaining: 1m 24s\n",
      "93:\tlearn: 0.2513080\ttotal: 19.6s\tremaining: 1m 24s\n",
      "94:\tlearn: 0.2507875\ttotal: 19.8s\tremaining: 1m 24s\n",
      "95:\tlearn: 0.2502262\ttotal: 20s\tremaining: 1m 24s\n",
      "96:\tlearn: 0.2497262\ttotal: 20.2s\tremaining: 1m 24s\n",
      "97:\tlearn: 0.2492377\ttotal: 20.4s\tremaining: 1m 23s\n",
      "98:\tlearn: 0.2487001\ttotal: 20.6s\tremaining: 1m 23s\n",
      "99:\tlearn: 0.2480745\ttotal: 20.9s\tremaining: 1m 23s\n",
      "100:\tlearn: 0.2476787\ttotal: 21.1s\tremaining: 1m 23s\n",
      "101:\tlearn: 0.2472738\ttotal: 21.3s\tremaining: 1m 22s\n",
      "102:\tlearn: 0.2468472\ttotal: 21.5s\tremaining: 1m 22s\n",
      "103:\tlearn: 0.2463662\ttotal: 21.7s\tremaining: 1m 22s\n",
      "104:\tlearn: 0.2458380\ttotal: 21.9s\tremaining: 1m 22s\n",
      "105:\tlearn: 0.2453311\ttotal: 22.1s\tremaining: 1m 22s\n",
      "106:\tlearn: 0.2448504\ttotal: 22.3s\tremaining: 1m 22s\n",
      "107:\tlearn: 0.2444075\ttotal: 22.6s\tremaining: 1m 21s\n",
      "108:\tlearn: 0.2439575\ttotal: 22.8s\tremaining: 1m 21s\n",
      "109:\tlearn: 0.2434547\ttotal: 23s\tremaining: 1m 21s\n",
      "110:\tlearn: 0.2429883\ttotal: 23.2s\tremaining: 1m 21s\n",
      "111:\tlearn: 0.2425594\ttotal: 23.4s\tremaining: 1m 21s\n",
      "112:\tlearn: 0.2420469\ttotal: 23.6s\tremaining: 1m 20s\n",
      "113:\tlearn: 0.2415349\ttotal: 23.8s\tremaining: 1m 20s\n",
      "114:\tlearn: 0.2410408\ttotal: 24s\tremaining: 1m 20s\n",
      "115:\tlearn: 0.2406485\ttotal: 24.2s\tremaining: 1m 20s\n",
      "116:\tlearn: 0.2402435\ttotal: 24.4s\tremaining: 1m 20s\n",
      "117:\tlearn: 0.2398231\ttotal: 24.7s\tremaining: 1m 19s\n",
      "118:\tlearn: 0.2394156\ttotal: 24.9s\tremaining: 1m 19s\n",
      "119:\tlearn: 0.2389217\ttotal: 25.2s\tremaining: 1m 19s\n",
      "120:\tlearn: 0.2385198\ttotal: 25.4s\tremaining: 1m 19s\n",
      "121:\tlearn: 0.2380702\ttotal: 25.6s\tremaining: 1m 19s\n",
      "122:\tlearn: 0.2375681\ttotal: 25.8s\tremaining: 1m 19s\n",
      "123:\tlearn: 0.2371255\ttotal: 26.1s\tremaining: 1m 19s\n",
      "124:\tlearn: 0.2366552\ttotal: 26.3s\tremaining: 1m 18s\n",
      "125:\tlearn: 0.2362004\ttotal: 26.5s\tremaining: 1m 18s\n",
      "126:\tlearn: 0.2357801\ttotal: 26.7s\tremaining: 1m 18s\n",
      "127:\tlearn: 0.2353123\ttotal: 26.9s\tremaining: 1m 18s\n",
      "128:\tlearn: 0.2349157\ttotal: 27.2s\tremaining: 1m 18s\n",
      "129:\tlearn: 0.2344313\ttotal: 27.4s\tremaining: 1m 17s\n",
      "130:\tlearn: 0.2339384\ttotal: 27.6s\tremaining: 1m 17s\n",
      "131:\tlearn: 0.2334857\ttotal: 27.8s\tremaining: 1m 17s\n",
      "132:\tlearn: 0.2330081\ttotal: 28.1s\tremaining: 1m 17s\n",
      "133:\tlearn: 0.2324910\ttotal: 28.3s\tremaining: 1m 17s\n",
      "134:\tlearn: 0.2319428\ttotal: 28.6s\tremaining: 1m 17s\n",
      "135:\tlearn: 0.2314566\ttotal: 28.9s\tremaining: 1m 17s\n",
      "136:\tlearn: 0.2309725\ttotal: 29.1s\tremaining: 1m 17s\n",
      "137:\tlearn: 0.2304619\ttotal: 29.3s\tremaining: 1m 16s\n",
      "138:\tlearn: 0.2299349\ttotal: 29.5s\tremaining: 1m 16s\n",
      "139:\tlearn: 0.2294310\ttotal: 29.7s\tremaining: 1m 16s\n",
      "140:\tlearn: 0.2289483\ttotal: 29.9s\tremaining: 1m 16s\n",
      "141:\tlearn: 0.2284689\ttotal: 30.1s\tremaining: 1m 15s\n",
      "142:\tlearn: 0.2280025\ttotal: 30.3s\tremaining: 1m 15s\n",
      "143:\tlearn: 0.2274370\ttotal: 30.5s\tremaining: 1m 15s\n",
      "144:\tlearn: 0.2268840\ttotal: 30.7s\tremaining: 1m 15s\n",
      "145:\tlearn: 0.2264217\ttotal: 30.9s\tremaining: 1m 14s\n",
      "146:\tlearn: 0.2259311\ttotal: 31.1s\tremaining: 1m 14s\n",
      "147:\tlearn: 0.2254289\ttotal: 31.3s\tremaining: 1m 14s\n",
      "148:\tlearn: 0.2249392\ttotal: 31.5s\tremaining: 1m 14s\n",
      "149:\tlearn: 0.2244471\ttotal: 31.7s\tremaining: 1m 13s\n",
      "150:\tlearn: 0.2239085\ttotal: 31.9s\tremaining: 1m 13s\n",
      "151:\tlearn: 0.2233856\ttotal: 32.1s\tremaining: 1m 13s\n",
      "152:\tlearn: 0.2229438\ttotal: 32.3s\tremaining: 1m 13s\n",
      "153:\tlearn: 0.2225474\ttotal: 32.5s\tremaining: 1m 13s\n",
      "154:\tlearn: 0.2220930\ttotal: 32.7s\tremaining: 1m 12s\n",
      "155:\tlearn: 0.2215679\ttotal: 32.9s\tremaining: 1m 12s\n",
      "156:\tlearn: 0.2210769\ttotal: 33.1s\tremaining: 1m 12s\n",
      "157:\tlearn: 0.2207125\ttotal: 33.3s\tremaining: 1m 12s\n",
      "158:\tlearn: 0.2203436\ttotal: 33.5s\tremaining: 1m 11s\n",
      "159:\tlearn: 0.2199684\ttotal: 33.7s\tremaining: 1m 11s\n",
      "160:\tlearn: 0.2193753\ttotal: 33.9s\tremaining: 1m 11s\n",
      "161:\tlearn: 0.2190081\ttotal: 34s\tremaining: 1m 11s\n",
      "162:\tlearn: 0.2185019\ttotal: 34.2s\tremaining: 1m 10s\n",
      "163:\tlearn: 0.2180532\ttotal: 34.4s\tremaining: 1m 10s\n",
      "164:\tlearn: 0.2174750\ttotal: 34.6s\tremaining: 1m 10s\n",
      "165:\tlearn: 0.2170845\ttotal: 34.8s\tremaining: 1m 10s\n",
      "166:\tlearn: 0.2167157\ttotal: 35s\tremaining: 1m 9s\n",
      "167:\tlearn: 0.2162406\ttotal: 35.2s\tremaining: 1m 9s\n",
      "168:\tlearn: 0.2157473\ttotal: 35.4s\tremaining: 1m 9s\n",
      "169:\tlearn: 0.2153065\ttotal: 35.6s\tremaining: 1m 9s\n",
      "170:\tlearn: 0.2147898\ttotal: 35.8s\tremaining: 1m 8s\n",
      "171:\tlearn: 0.2142854\ttotal: 36s\tremaining: 1m 8s\n",
      "172:\tlearn: 0.2138274\ttotal: 36.2s\tremaining: 1m 8s\n",
      "173:\tlearn: 0.2133581\ttotal: 36.4s\tremaining: 1m 8s\n",
      "174:\tlearn: 0.2129189\ttotal: 36.6s\tremaining: 1m 7s\n",
      "175:\tlearn: 0.2124394\ttotal: 36.7s\tremaining: 1m 7s\n",
      "176:\tlearn: 0.2120174\ttotal: 36.9s\tremaining: 1m 7s\n",
      "177:\tlearn: 0.2114177\ttotal: 37.1s\tremaining: 1m 7s\n",
      "178:\tlearn: 0.2109479\ttotal: 37.3s\tremaining: 1m 6s\n",
      "179:\tlearn: 0.2104961\ttotal: 37.5s\tremaining: 1m 6s\n",
      "180:\tlearn: 0.2100698\ttotal: 37.7s\tremaining: 1m 6s\n",
      "181:\tlearn: 0.2096605\ttotal: 37.9s\tremaining: 1m 6s\n",
      "182:\tlearn: 0.2091800\ttotal: 38.1s\tremaining: 1m 6s\n",
      "183:\tlearn: 0.2087960\ttotal: 38.3s\tremaining: 1m 5s\n",
      "184:\tlearn: 0.2083359\ttotal: 38.5s\tremaining: 1m 5s\n",
      "185:\tlearn: 0.2078471\ttotal: 38.7s\tremaining: 1m 5s\n",
      "186:\tlearn: 0.2074722\ttotal: 38.9s\tremaining: 1m 5s\n",
      "187:\tlearn: 0.2069648\ttotal: 39.1s\tremaining: 1m 4s\n",
      "188:\tlearn: 0.2065746\ttotal: 39.3s\tremaining: 1m 4s\n",
      "189:\tlearn: 0.2061329\ttotal: 39.5s\tremaining: 1m 4s\n",
      "190:\tlearn: 0.2056180\ttotal: 39.7s\tremaining: 1m 4s\n",
      "191:\tlearn: 0.2051443\ttotal: 39.9s\tremaining: 1m 3s\n",
      "192:\tlearn: 0.2046956\ttotal: 40.1s\tremaining: 1m 3s\n",
      "193:\tlearn: 0.2043937\ttotal: 40.2s\tremaining: 1m 3s\n",
      "194:\tlearn: 0.2039516\ttotal: 40.4s\tremaining: 1m 3s\n",
      "195:\tlearn: 0.2035516\ttotal: 40.6s\tremaining: 1m 3s\n",
      "196:\tlearn: 0.2031764\ttotal: 40.8s\tremaining: 1m 2s\n",
      "197:\tlearn: 0.2027718\ttotal: 41s\tremaining: 1m 2s\n",
      "198:\tlearn: 0.2024509\ttotal: 41.2s\tremaining: 1m 2s\n",
      "199:\tlearn: 0.2019881\ttotal: 41.4s\tremaining: 1m 2s\n",
      "200:\tlearn: 0.2015529\ttotal: 41.6s\tremaining: 1m 1s\n",
      "201:\tlearn: 0.2010721\ttotal: 41.8s\tremaining: 1m 1s\n",
      "202:\tlearn: 0.2006435\ttotal: 42s\tremaining: 1m 1s\n",
      "203:\tlearn: 0.2001796\ttotal: 42.2s\tremaining: 1m 1s\n",
      "204:\tlearn: 0.1997918\ttotal: 42.4s\tremaining: 1m\n",
      "205:\tlearn: 0.1993118\ttotal: 42.6s\tremaining: 1m\n",
      "206:\tlearn: 0.1988307\ttotal: 42.8s\tremaining: 1m\n",
      "207:\tlearn: 0.1983810\ttotal: 43s\tremaining: 1m\n",
      "208:\tlearn: 0.1979208\ttotal: 43.2s\tremaining: 1m\n",
      "209:\tlearn: 0.1974624\ttotal: 43.4s\tremaining: 59.9s\n",
      "210:\tlearn: 0.1971458\ttotal: 43.6s\tremaining: 59.7s\n",
      "211:\tlearn: 0.1968006\ttotal: 43.7s\tremaining: 59.4s\n",
      "212:\tlearn: 0.1964418\ttotal: 43.9s\tremaining: 59.2s\n",
      "213:\tlearn: 0.1960006\ttotal: 44.1s\tremaining: 59s\n",
      "214:\tlearn: 0.1955686\ttotal: 44.3s\tremaining: 58.7s\n",
      "215:\tlearn: 0.1952297\ttotal: 44.5s\tremaining: 58.5s\n",
      "216:\tlearn: 0.1947745\ttotal: 44.7s\tremaining: 58.3s\n",
      "217:\tlearn: 0.1944713\ttotal: 44.9s\tremaining: 58.1s\n",
      "218:\tlearn: 0.1940594\ttotal: 45.1s\tremaining: 57.9s\n",
      "219:\tlearn: 0.1936758\ttotal: 45.3s\tremaining: 57.6s\n",
      "220:\tlearn: 0.1933690\ttotal: 45.5s\tremaining: 57.4s\n",
      "221:\tlearn: 0.1929651\ttotal: 45.7s\tremaining: 57.2s\n",
      "222:\tlearn: 0.1925548\ttotal: 45.9s\tremaining: 57s\n",
      "223:\tlearn: 0.1922068\ttotal: 46.1s\tremaining: 56.8s\n",
      "224:\tlearn: 0.1919363\ttotal: 46.2s\tremaining: 56.5s\n",
      "225:\tlearn: 0.1915450\ttotal: 46.4s\tremaining: 56.3s\n",
      "226:\tlearn: 0.1913126\ttotal: 46.6s\tremaining: 56.1s\n",
      "227:\tlearn: 0.1909479\ttotal: 46.8s\tremaining: 55.8s\n",
      "228:\tlearn: 0.1906098\ttotal: 47s\tremaining: 55.6s\n",
      "229:\tlearn: 0.1903342\ttotal: 47.2s\tremaining: 55.4s\n",
      "230:\tlearn: 0.1899753\ttotal: 47.4s\tremaining: 55.2s\n",
      "231:\tlearn: 0.1895451\ttotal: 47.6s\tremaining: 55s\n",
      "232:\tlearn: 0.1891532\ttotal: 47.8s\tremaining: 54.7s\n",
      "233:\tlearn: 0.1886964\ttotal: 48s\tremaining: 54.6s\n",
      "234:\tlearn: 0.1884627\ttotal: 48.2s\tremaining: 54.4s\n",
      "235:\tlearn: 0.1881123\ttotal: 48.4s\tremaining: 54.1s\n",
      "236:\tlearn: 0.1877271\ttotal: 48.6s\tremaining: 53.9s\n",
      "237:\tlearn: 0.1874606\ttotal: 48.8s\tremaining: 53.7s\n",
      "238:\tlearn: 0.1870582\ttotal: 49s\tremaining: 53.5s\n",
      "239:\tlearn: 0.1867145\ttotal: 49.2s\tremaining: 53.4s\n",
      "240:\tlearn: 0.1864246\ttotal: 49.4s\tremaining: 53.1s\n",
      "241:\tlearn: 0.1860172\ttotal: 49.6s\tremaining: 52.9s\n",
      "242:\tlearn: 0.1856577\ttotal: 49.8s\tremaining: 52.7s\n",
      "243:\tlearn: 0.1852769\ttotal: 50.1s\tremaining: 52.5s\n",
      "244:\tlearn: 0.1849333\ttotal: 50.3s\tremaining: 52.3s\n",
      "245:\tlearn: 0.1845454\ttotal: 50.5s\tremaining: 52.1s\n",
      "246:\tlearn: 0.1842636\ttotal: 50.7s\tremaining: 51.9s\n",
      "247:\tlearn: 0.1838565\ttotal: 50.9s\tremaining: 51.7s\n",
      "248:\tlearn: 0.1834581\ttotal: 51.1s\tremaining: 51.5s\n",
      "249:\tlearn: 0.1831279\ttotal: 51.3s\tremaining: 51.3s\n",
      "250:\tlearn: 0.1827865\ttotal: 51.5s\tremaining: 51.1s\n",
      "251:\tlearn: 0.1824692\ttotal: 51.7s\tremaining: 50.9s\n",
      "252:\tlearn: 0.1821192\ttotal: 51.9s\tremaining: 50.7s\n",
      "253:\tlearn: 0.1818699\ttotal: 52.1s\tremaining: 50.5s\n",
      "254:\tlearn: 0.1816849\ttotal: 52.3s\tremaining: 50.2s\n",
      "255:\tlearn: 0.1813298\ttotal: 52.5s\tremaining: 50s\n",
      "256:\tlearn: 0.1810081\ttotal: 52.7s\tremaining: 49.8s\n",
      "257:\tlearn: 0.1807123\ttotal: 52.9s\tremaining: 49.6s\n",
      "258:\tlearn: 0.1803224\ttotal: 53.1s\tremaining: 49.4s\n",
      "259:\tlearn: 0.1799604\ttotal: 53.3s\tremaining: 49.2s\n",
      "260:\tlearn: 0.1796276\ttotal: 53.5s\tremaining: 49s\n",
      "261:\tlearn: 0.1792770\ttotal: 53.8s\tremaining: 48.8s\n",
      "262:\tlearn: 0.1789694\ttotal: 54s\tremaining: 48.6s\n",
      "263:\tlearn: 0.1786185\ttotal: 54.2s\tremaining: 48.4s\n",
      "264:\tlearn: 0.1781872\ttotal: 54.4s\tremaining: 48.2s\n",
      "265:\tlearn: 0.1779244\ttotal: 54.6s\tremaining: 48s\n",
      "266:\tlearn: 0.1776086\ttotal: 54.8s\tremaining: 47.8s\n",
      "267:\tlearn: 0.1772736\ttotal: 55s\tremaining: 47.6s\n",
      "268:\tlearn: 0.1769755\ttotal: 55.2s\tremaining: 47.4s\n",
      "269:\tlearn: 0.1767264\ttotal: 55.4s\tremaining: 47.2s\n",
      "270:\tlearn: 0.1763685\ttotal: 55.6s\tremaining: 47s\n",
      "271:\tlearn: 0.1760001\ttotal: 55.8s\tremaining: 46.8s\n",
      "272:\tlearn: 0.1756372\ttotal: 56s\tremaining: 46.6s\n",
      "273:\tlearn: 0.1753505\ttotal: 56.3s\tremaining: 46.4s\n",
      "274:\tlearn: 0.1751014\ttotal: 56.4s\tremaining: 46.2s\n",
      "275:\tlearn: 0.1747867\ttotal: 56.6s\tremaining: 46s\n",
      "276:\tlearn: 0.1745031\ttotal: 56.9s\tremaining: 45.8s\n",
      "277:\tlearn: 0.1741593\ttotal: 57.1s\tremaining: 45.6s\n",
      "278:\tlearn: 0.1738549\ttotal: 57.3s\tremaining: 45.4s\n",
      "279:\tlearn: 0.1735858\ttotal: 57.5s\tremaining: 45.2s\n",
      "280:\tlearn: 0.1732314\ttotal: 57.7s\tremaining: 45s\n",
      "281:\tlearn: 0.1728954\ttotal: 57.9s\tremaining: 44.8s\n",
      "282:\tlearn: 0.1726959\ttotal: 58.1s\tremaining: 44.6s\n",
      "283:\tlearn: 0.1723867\ttotal: 58.3s\tremaining: 44.3s\n",
      "284:\tlearn: 0.1720706\ttotal: 58.5s\tremaining: 44.1s\n",
      "285:\tlearn: 0.1716706\ttotal: 58.7s\tremaining: 43.9s\n",
      "286:\tlearn: 0.1713948\ttotal: 58.9s\tremaining: 43.7s\n",
      "287:\tlearn: 0.1711615\ttotal: 59.1s\tremaining: 43.5s\n",
      "288:\tlearn: 0.1707953\ttotal: 59.3s\tremaining: 43.3s\n",
      "289:\tlearn: 0.1704231\ttotal: 59.5s\tremaining: 43.1s\n",
      "290:\tlearn: 0.1701684\ttotal: 59.7s\tremaining: 42.9s\n",
      "291:\tlearn: 0.1699557\ttotal: 59.8s\tremaining: 42.6s\n",
      "292:\tlearn: 0.1697759\ttotal: 1m\tremaining: 42.4s\n",
      "293:\tlearn: 0.1694754\ttotal: 1m\tremaining: 42.2s\n",
      "294:\tlearn: 0.1691180\ttotal: 1m\tremaining: 42s\n",
      "295:\tlearn: 0.1687456\ttotal: 1m\tremaining: 41.8s\n",
      "296:\tlearn: 0.1684494\ttotal: 1m\tremaining: 41.6s\n",
      "297:\tlearn: 0.1681008\ttotal: 1m 1s\tremaining: 41.4s\n",
      "298:\tlearn: 0.1677892\ttotal: 1m 1s\tremaining: 41.1s\n",
      "299:\tlearn: 0.1675013\ttotal: 1m 1s\tremaining: 40.9s\n",
      "300:\tlearn: 0.1673005\ttotal: 1m 1s\tremaining: 40.7s\n",
      "301:\tlearn: 0.1670121\ttotal: 1m 1s\tremaining: 40.5s\n",
      "302:\tlearn: 0.1667265\ttotal: 1m 1s\tremaining: 40.3s\n",
      "303:\tlearn: 0.1664144\ttotal: 1m 2s\tremaining: 40.1s\n",
      "304:\tlearn: 0.1661290\ttotal: 1m 2s\tremaining: 39.9s\n",
      "305:\tlearn: 0.1658325\ttotal: 1m 2s\tremaining: 39.7s\n",
      "306:\tlearn: 0.1655923\ttotal: 1m 2s\tremaining: 39.4s\n",
      "307:\tlearn: 0.1652568\ttotal: 1m 2s\tremaining: 39.2s\n",
      "308:\tlearn: 0.1648662\ttotal: 1m 3s\tremaining: 39s\n",
      "309:\tlearn: 0.1645052\ttotal: 1m 3s\tremaining: 38.8s\n",
      "310:\tlearn: 0.1642102\ttotal: 1m 3s\tremaining: 38.6s\n",
      "311:\tlearn: 0.1638474\ttotal: 1m 3s\tremaining: 38.4s\n",
      "312:\tlearn: 0.1635341\ttotal: 1m 3s\tremaining: 38.2s\n",
      "313:\tlearn: 0.1631485\ttotal: 1m 4s\tremaining: 38s\n",
      "314:\tlearn: 0.1629133\ttotal: 1m 4s\tremaining: 37.8s\n",
      "315:\tlearn: 0.1626544\ttotal: 1m 4s\tremaining: 37.6s\n",
      "316:\tlearn: 0.1623570\ttotal: 1m 4s\tremaining: 37.4s\n",
      "317:\tlearn: 0.1620310\ttotal: 1m 4s\tremaining: 37.2s\n",
      "318:\tlearn: 0.1616563\ttotal: 1m 5s\tremaining: 37s\n",
      "319:\tlearn: 0.1614625\ttotal: 1m 5s\tremaining: 36.7s\n",
      "320:\tlearn: 0.1612069\ttotal: 1m 5s\tremaining: 36.5s\n",
      "321:\tlearn: 0.1610691\ttotal: 1m 5s\tremaining: 36.3s\n",
      "322:\tlearn: 0.1607703\ttotal: 1m 5s\tremaining: 36.1s\n",
      "323:\tlearn: 0.1604579\ttotal: 1m 6s\tremaining: 35.9s\n",
      "324:\tlearn: 0.1600687\ttotal: 1m 6s\tremaining: 35.7s\n",
      "325:\tlearn: 0.1598741\ttotal: 1m 6s\tremaining: 35.4s\n",
      "326:\tlearn: 0.1596539\ttotal: 1m 6s\tremaining: 35.2s\n",
      "327:\tlearn: 0.1593566\ttotal: 1m 6s\tremaining: 35s\n",
      "328:\tlearn: 0.1590980\ttotal: 1m 6s\tremaining: 34.8s\n",
      "329:\tlearn: 0.1588070\ttotal: 1m 7s\tremaining: 34.6s\n",
      "330:\tlearn: 0.1586035\ttotal: 1m 7s\tremaining: 34.4s\n",
      "331:\tlearn: 0.1584052\ttotal: 1m 7s\tremaining: 34.2s\n",
      "332:\tlearn: 0.1581307\ttotal: 1m 7s\tremaining: 34s\n",
      "333:\tlearn: 0.1577828\ttotal: 1m 7s\tremaining: 33.8s\n",
      "334:\tlearn: 0.1575203\ttotal: 1m 8s\tremaining: 33.6s\n",
      "335:\tlearn: 0.1572201\ttotal: 1m 8s\tremaining: 33.3s\n",
      "336:\tlearn: 0.1569048\ttotal: 1m 8s\tremaining: 33.1s\n",
      "337:\tlearn: 0.1566207\ttotal: 1m 8s\tremaining: 32.9s\n",
      "338:\tlearn: 0.1563586\ttotal: 1m 8s\tremaining: 32.7s\n",
      "339:\tlearn: 0.1561036\ttotal: 1m 9s\tremaining: 32.5s\n",
      "340:\tlearn: 0.1557818\ttotal: 1m 9s\tremaining: 32.3s\n",
      "341:\tlearn: 0.1555483\ttotal: 1m 9s\tremaining: 32.1s\n",
      "342:\tlearn: 0.1552387\ttotal: 1m 9s\tremaining: 31.9s\n",
      "343:\tlearn: 0.1549850\ttotal: 1m 9s\tremaining: 31.7s\n",
      "344:\tlearn: 0.1546676\ttotal: 1m 10s\tremaining: 31.5s\n",
      "345:\tlearn: 0.1544247\ttotal: 1m 10s\tremaining: 31.3s\n",
      "346:\tlearn: 0.1540965\ttotal: 1m 10s\tremaining: 31.1s\n",
      "347:\tlearn: 0.1538136\ttotal: 1m 10s\tremaining: 30.8s\n",
      "348:\tlearn: 0.1536245\ttotal: 1m 10s\tremaining: 30.6s\n",
      "349:\tlearn: 0.1533128\ttotal: 1m 10s\tremaining: 30.4s\n",
      "350:\tlearn: 0.1530183\ttotal: 1m 11s\tremaining: 30.2s\n",
      "351:\tlearn: 0.1527284\ttotal: 1m 11s\tremaining: 30s\n",
      "352:\tlearn: 0.1524656\ttotal: 1m 11s\tremaining: 29.8s\n",
      "353:\tlearn: 0.1523117\ttotal: 1m 11s\tremaining: 29.6s\n",
      "354:\tlearn: 0.1520545\ttotal: 1m 11s\tremaining: 29.4s\n",
      "355:\tlearn: 0.1517394\ttotal: 1m 12s\tremaining: 29.2s\n",
      "356:\tlearn: 0.1515631\ttotal: 1m 12s\tremaining: 29s\n",
      "357:\tlearn: 0.1513217\ttotal: 1m 12s\tremaining: 28.8s\n",
      "358:\tlearn: 0.1510383\ttotal: 1m 12s\tremaining: 28.6s\n",
      "359:\tlearn: 0.1507852\ttotal: 1m 12s\tremaining: 28.3s\n",
      "360:\tlearn: 0.1504770\ttotal: 1m 13s\tremaining: 28.1s\n",
      "361:\tlearn: 0.1502966\ttotal: 1m 13s\tremaining: 27.9s\n",
      "362:\tlearn: 0.1499665\ttotal: 1m 13s\tremaining: 27.7s\n",
      "363:\tlearn: 0.1496586\ttotal: 1m 13s\tremaining: 27.5s\n",
      "364:\tlearn: 0.1494214\ttotal: 1m 13s\tremaining: 27.3s\n",
      "365:\tlearn: 0.1490807\ttotal: 1m 14s\tremaining: 27.1s\n",
      "366:\tlearn: 0.1488157\ttotal: 1m 14s\tremaining: 26.9s\n",
      "367:\tlearn: 0.1485057\ttotal: 1m 14s\tremaining: 26.7s\n",
      "368:\tlearn: 0.1483351\ttotal: 1m 14s\tremaining: 26.5s\n",
      "369:\tlearn: 0.1479795\ttotal: 1m 14s\tremaining: 26.3s\n",
      "370:\tlearn: 0.1477903\ttotal: 1m 14s\tremaining: 26.1s\n",
      "371:\tlearn: 0.1475655\ttotal: 1m 15s\tremaining: 25.9s\n",
      "372:\tlearn: 0.1472308\ttotal: 1m 15s\tremaining: 25.7s\n",
      "373:\tlearn: 0.1469286\ttotal: 1m 15s\tremaining: 25.5s\n",
      "374:\tlearn: 0.1466578\ttotal: 1m 15s\tremaining: 25.3s\n",
      "375:\tlearn: 0.1464348\ttotal: 1m 15s\tremaining: 25s\n",
      "376:\tlearn: 0.1461573\ttotal: 1m 16s\tremaining: 24.8s\n",
      "377:\tlearn: 0.1458484\ttotal: 1m 16s\tremaining: 24.6s\n",
      "378:\tlearn: 0.1455101\ttotal: 1m 16s\tremaining: 24.4s\n",
      "379:\tlearn: 0.1451706\ttotal: 1m 16s\tremaining: 24.2s\n",
      "380:\tlearn: 0.1450209\ttotal: 1m 16s\tremaining: 24s\n",
      "381:\tlearn: 0.1447666\ttotal: 1m 17s\tremaining: 23.8s\n",
      "382:\tlearn: 0.1444542\ttotal: 1m 17s\tremaining: 23.6s\n",
      "383:\tlearn: 0.1441612\ttotal: 1m 17s\tremaining: 23.4s\n",
      "384:\tlearn: 0.1439190\ttotal: 1m 17s\tremaining: 23.2s\n",
      "385:\tlearn: 0.1437031\ttotal: 1m 17s\tremaining: 23s\n",
      "386:\tlearn: 0.1434756\ttotal: 1m 18s\tremaining: 22.8s\n",
      "387:\tlearn: 0.1432108\ttotal: 1m 18s\tremaining: 22.6s\n",
      "388:\tlearn: 0.1430333\ttotal: 1m 18s\tremaining: 22.4s\n",
      "389:\tlearn: 0.1428139\ttotal: 1m 18s\tremaining: 22.2s\n",
      "390:\tlearn: 0.1425143\ttotal: 1m 18s\tremaining: 22s\n",
      "391:\tlearn: 0.1422596\ttotal: 1m 19s\tremaining: 21.8s\n",
      "392:\tlearn: 0.1420032\ttotal: 1m 19s\tremaining: 21.6s\n",
      "393:\tlearn: 0.1417920\ttotal: 1m 19s\tremaining: 21.4s\n",
      "394:\tlearn: 0.1414884\ttotal: 1m 19s\tremaining: 21.2s\n",
      "395:\tlearn: 0.1412475\ttotal: 1m 19s\tremaining: 21s\n",
      "396:\tlearn: 0.1409910\ttotal: 1m 20s\tremaining: 20.8s\n",
      "397:\tlearn: 0.1407890\ttotal: 1m 20s\tremaining: 20.6s\n",
      "398:\tlearn: 0.1405843\ttotal: 1m 20s\tremaining: 20.4s\n",
      "399:\tlearn: 0.1403790\ttotal: 1m 20s\tremaining: 20.2s\n",
      "400:\tlearn: 0.1401350\ttotal: 1m 20s\tremaining: 20s\n",
      "401:\tlearn: 0.1399402\ttotal: 1m 21s\tremaining: 19.8s\n",
      "402:\tlearn: 0.1396966\ttotal: 1m 21s\tremaining: 19.6s\n",
      "403:\tlearn: 0.1393913\ttotal: 1m 21s\tremaining: 19.4s\n",
      "404:\tlearn: 0.1391784\ttotal: 1m 21s\tremaining: 19.2s\n",
      "405:\tlearn: 0.1389875\ttotal: 1m 21s\tremaining: 19s\n",
      "406:\tlearn: 0.1387519\ttotal: 1m 22s\tremaining: 18.8s\n",
      "407:\tlearn: 0.1385311\ttotal: 1m 22s\tremaining: 18.6s\n",
      "408:\tlearn: 0.1382560\ttotal: 1m 22s\tremaining: 18.4s\n",
      "409:\tlearn: 0.1380384\ttotal: 1m 22s\tremaining: 18.2s\n",
      "410:\tlearn: 0.1377497\ttotal: 1m 23s\tremaining: 18s\n",
      "411:\tlearn: 0.1375305\ttotal: 1m 23s\tremaining: 17.8s\n",
      "412:\tlearn: 0.1373555\ttotal: 1m 23s\tremaining: 17.6s\n",
      "413:\tlearn: 0.1371264\ttotal: 1m 23s\tremaining: 17.4s\n",
      "414:\tlearn: 0.1368785\ttotal: 1m 23s\tremaining: 17.2s\n",
      "415:\tlearn: 0.1365954\ttotal: 1m 24s\tremaining: 17s\n",
      "416:\tlearn: 0.1363393\ttotal: 1m 24s\tremaining: 16.8s\n",
      "417:\tlearn: 0.1361851\ttotal: 1m 24s\tremaining: 16.6s\n",
      "418:\tlearn: 0.1359422\ttotal: 1m 24s\tremaining: 16.4s\n",
      "419:\tlearn: 0.1358453\ttotal: 1m 24s\tremaining: 16.2s\n",
      "420:\tlearn: 0.1357049\ttotal: 1m 25s\tremaining: 16s\n",
      "421:\tlearn: 0.1354856\ttotal: 1m 25s\tremaining: 15.8s\n",
      "422:\tlearn: 0.1352230\ttotal: 1m 25s\tremaining: 15.6s\n",
      "423:\tlearn: 0.1349755\ttotal: 1m 25s\tremaining: 15.3s\n",
      "424:\tlearn: 0.1348048\ttotal: 1m 25s\tremaining: 15.1s\n",
      "425:\tlearn: 0.1345690\ttotal: 1m 26s\tremaining: 14.9s\n",
      "426:\tlearn: 0.1342594\ttotal: 1m 26s\tremaining: 14.7s\n",
      "427:\tlearn: 0.1340310\ttotal: 1m 26s\tremaining: 14.5s\n",
      "428:\tlearn: 0.1337873\ttotal: 1m 26s\tremaining: 14.3s\n",
      "429:\tlearn: 0.1335316\ttotal: 1m 26s\tremaining: 14.1s\n",
      "430:\tlearn: 0.1332991\ttotal: 1m 27s\tremaining: 13.9s\n",
      "431:\tlearn: 0.1330346\ttotal: 1m 27s\tremaining: 13.7s\n",
      "432:\tlearn: 0.1327628\ttotal: 1m 27s\tremaining: 13.5s\n",
      "433:\tlearn: 0.1324998\ttotal: 1m 27s\tremaining: 13.4s\n",
      "434:\tlearn: 0.1323472\ttotal: 1m 28s\tremaining: 13.2s\n",
      "435:\tlearn: 0.1321564\ttotal: 1m 28s\tremaining: 13s\n",
      "436:\tlearn: 0.1320307\ttotal: 1m 28s\tremaining: 12.7s\n",
      "437:\tlearn: 0.1318489\ttotal: 1m 28s\tremaining: 12.5s\n",
      "438:\tlearn: 0.1316304\ttotal: 1m 28s\tremaining: 12.3s\n",
      "439:\tlearn: 0.1313752\ttotal: 1m 29s\tremaining: 12.1s\n",
      "440:\tlearn: 0.1311159\ttotal: 1m 29s\tremaining: 11.9s\n",
      "441:\tlearn: 0.1308623\ttotal: 1m 29s\tremaining: 11.7s\n",
      "442:\tlearn: 0.1307444\ttotal: 1m 29s\tremaining: 11.5s\n",
      "443:\tlearn: 0.1305089\ttotal: 1m 29s\tremaining: 11.3s\n",
      "444:\tlearn: 0.1302435\ttotal: 1m 29s\tremaining: 11.1s\n",
      "445:\tlearn: 0.1300284\ttotal: 1m 30s\tremaining: 10.9s\n",
      "446:\tlearn: 0.1297431\ttotal: 1m 30s\tremaining: 10.7s\n",
      "447:\tlearn: 0.1295051\ttotal: 1m 30s\tremaining: 10.5s\n",
      "448:\tlearn: 0.1293018\ttotal: 1m 30s\tremaining: 10.3s\n",
      "449:\tlearn: 0.1290836\ttotal: 1m 30s\tremaining: 10.1s\n",
      "450:\tlearn: 0.1289494\ttotal: 1m 31s\tremaining: 9.9s\n",
      "451:\tlearn: 0.1287428\ttotal: 1m 31s\tremaining: 9.7s\n",
      "452:\tlearn: 0.1284831\ttotal: 1m 31s\tremaining: 9.5s\n",
      "453:\tlearn: 0.1281812\ttotal: 1m 31s\tremaining: 9.29s\n",
      "454:\tlearn: 0.1279289\ttotal: 1m 31s\tremaining: 9.09s\n",
      "455:\tlearn: 0.1276996\ttotal: 1m 32s\tremaining: 8.89s\n",
      "456:\tlearn: 0.1274826\ttotal: 1m 32s\tremaining: 8.69s\n",
      "457:\tlearn: 0.1272736\ttotal: 1m 32s\tremaining: 8.48s\n",
      "458:\tlearn: 0.1270026\ttotal: 1m 32s\tremaining: 8.28s\n",
      "459:\tlearn: 0.1267164\ttotal: 1m 32s\tremaining: 8.08s\n",
      "460:\tlearn: 0.1265304\ttotal: 1m 33s\tremaining: 7.88s\n",
      "461:\tlearn: 0.1263656\ttotal: 1m 33s\tremaining: 7.67s\n",
      "462:\tlearn: 0.1262067\ttotal: 1m 33s\tremaining: 7.47s\n",
      "463:\tlearn: 0.1259197\ttotal: 1m 33s\tremaining: 7.27s\n",
      "464:\tlearn: 0.1257498\ttotal: 1m 33s\tremaining: 7.07s\n",
      "465:\tlearn: 0.1256051\ttotal: 1m 34s\tremaining: 6.87s\n",
      "466:\tlearn: 0.1253853\ttotal: 1m 34s\tremaining: 6.66s\n",
      "467:\tlearn: 0.1251088\ttotal: 1m 34s\tremaining: 6.46s\n",
      "468:\tlearn: 0.1248857\ttotal: 1m 34s\tremaining: 6.26s\n",
      "469:\tlearn: 0.1247134\ttotal: 1m 34s\tremaining: 6.05s\n",
      "470:\tlearn: 0.1245344\ttotal: 1m 35s\tremaining: 5.85s\n",
      "471:\tlearn: 0.1242937\ttotal: 1m 35s\tremaining: 5.65s\n",
      "472:\tlearn: 0.1240829\ttotal: 1m 35s\tremaining: 5.45s\n",
      "473:\tlearn: 0.1239739\ttotal: 1m 35s\tremaining: 5.25s\n",
      "474:\tlearn: 0.1238285\ttotal: 1m 35s\tremaining: 5.04s\n",
      "475:\tlearn: 0.1235893\ttotal: 1m 36s\tremaining: 4.84s\n",
      "476:\tlearn: 0.1233761\ttotal: 1m 36s\tremaining: 4.64s\n",
      "477:\tlearn: 0.1231265\ttotal: 1m 36s\tremaining: 4.44s\n",
      "478:\tlearn: 0.1228705\ttotal: 1m 36s\tremaining: 4.24s\n",
      "479:\tlearn: 0.1226941\ttotal: 1m 36s\tremaining: 4.03s\n",
      "480:\tlearn: 0.1224773\ttotal: 1m 36s\tremaining: 3.83s\n",
      "481:\tlearn: 0.1222661\ttotal: 1m 37s\tremaining: 3.63s\n",
      "482:\tlearn: 0.1220054\ttotal: 1m 37s\tremaining: 3.43s\n",
      "483:\tlearn: 0.1218004\ttotal: 1m 37s\tremaining: 3.23s\n",
      "484:\tlearn: 0.1215900\ttotal: 1m 37s\tremaining: 3.02s\n",
      "485:\tlearn: 0.1213675\ttotal: 1m 37s\tremaining: 2.82s\n",
      "486:\tlearn: 0.1212188\ttotal: 1m 38s\tremaining: 2.62s\n",
      "487:\tlearn: 0.1209708\ttotal: 1m 38s\tremaining: 2.42s\n",
      "488:\tlearn: 0.1207107\ttotal: 1m 38s\tremaining: 2.22s\n",
      "489:\tlearn: 0.1205063\ttotal: 1m 38s\tremaining: 2.01s\n",
      "490:\tlearn: 0.1203516\ttotal: 1m 38s\tremaining: 1.81s\n",
      "491:\tlearn: 0.1201582\ttotal: 1m 39s\tremaining: 1.61s\n",
      "492:\tlearn: 0.1199069\ttotal: 1m 39s\tremaining: 1.41s\n",
      "493:\tlearn: 0.1197470\ttotal: 1m 39s\tremaining: 1.21s\n",
      "494:\tlearn: 0.1195583\ttotal: 1m 39s\tremaining: 1.01s\n",
      "495:\tlearn: 0.1193522\ttotal: 1m 39s\tremaining: 806ms\n",
      "496:\tlearn: 0.1191372\ttotal: 1m 40s\tremaining: 604ms\n",
      "497:\tlearn: 0.1189452\ttotal: 1m 40s\tremaining: 403ms\n",
      "498:\tlearn: 0.1188001\ttotal: 1m 40s\tremaining: 201ms\n",
      "499:\tlearn: 0.1185511\ttotal: 1m 40s\tremaining: 0us\n",
      "Wall time: 1min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2cc4e251248>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "CatBoost_clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.675\n"
     ]
    }
   ],
   "source": [
    "scoring_BERT(CatBoost_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Обучим модель градиентного бустинга  LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_params = {'n_estimators': [500],\n",
    "                   'learning_rate': [0.1, 0.3, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=17, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.3, 0.5],\n",
       "                         'n_estimators': [500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_clf_grid = GridSearchCV(lgbm_clf, lgbm_clf_params, scoring='f1')\n",
    "lgbm_clf_grid.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'learning_rate': 0.5, 'n_estimators': 500}\n",
      "best scores:  0.8977265596183712\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', lgbm_clf_grid.best_params_)\n",
    "print('best scores: ', lgbm_clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.5, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=17, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.674\n",
      "Wall time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring_BERT(lgbm_clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка модели на вменяемость\n",
    "Для того, чтобы получить «случайные» результаты, воспользуемся DummyClassifier. Полученные им результаты абсолютно случайные.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.495 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dummy_clf, features_train, labels_train, scoring='f1')\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка F1_score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.165\n"
     ]
    }
   ],
   "source": [
    "scoring_BERT(dummy_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что в среднем модель предсказывает 50/50. Что гораздо хуже рассмотренных выше моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по главе 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> В процессе обучения моделей обнаружили по TF-IDF:\n",
    "- Почти все модели показали значение f1 в районе 0.76.\n",
    "- Лучшей по метрики f1 является Логистическая XGBClassifier\n",
    "- Лучшей по времени обучения Логистическая Регрессия\n",
    "\n",
    ">  В процессе обучения моделей по BERT:\n",
    "- Почти все модели показали значение f1 в районе 0.67\n",
    "- Лучшей также является Логистическая Регрессия c результатом 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глава 3. Анализ моделей и общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем все модели на качество предсказания, скорость обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем все данные в таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Модель':['LogisticRegression', 'XGBClassifier', 'CatBoostClassifier', 'LGBMClassifier'], \n",
    "        'Скорость обучения':['Очень высокая', 'Высокая', 'Высокая', 'Очень высокая'],\n",
    "        'Качество предсказания по TF-IDF': [0.761, 0.775, 0.75, 0.76],\n",
    "        'Качество предсказания по BERT': [ 0.69, 0.676, 0.675, 0.674]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Скорость обучения</th>\n",
       "      <th>Качество предсказания по TF-IDF</th>\n",
       "      <th>Качество предсказания по BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Очень высокая</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Высокая</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>Высокая</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>Очень высокая</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель Скорость обучения  Качество предсказания по TF-IDF  \\\n",
       "0  LogisticRegression     Очень высокая                            0.761   \n",
       "1       XGBClassifier           Высокая                            0.775   \n",
       "2  CatBoostClassifier           Высокая                            0.750   \n",
       "3      LGBMClassifier     Очень высокая                            0.760   \n",
       "\n",
       "   Качество предсказания по BERT  \n",
       "0                          0.690  \n",
       "1                          0.676  \n",
       "2                          0.675  \n",
       "3                          0.674  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> По результатам исследований моделей для поставленной задачи наиболее оптимальными являются:\n",
    "- **LogisticRegression**  \n",
    "\n",
    ">**LogisticRegression** -  базовая модель, показывает хорошие показатели метрик и скорости обучения и предсказания, очень проста в настройке и не требует особой настройки гиперпараметров по сетке. Очень хорошо работает с предобработанными данными, т.е. после TF-IDF.     \n",
    "В целом все модели дают хорошие показатели метрики, но по скорости обучения отличаются.\n",
    "\n",
    "> Представление текста в векторную форму через BERT проще, т.к. не требует предварительной лемматизации, но есть свои особенности в настройки модели. \n",
    "\n",
    ">Для данной задачи лучшая для заказчика в плане качества предсказания, скорости предсказания, время обучения - **LogisticRegression**.     \n",
    "Т.к. лучше всего работает с предобработанными данными и имеет самую высокую скорость обучения, как все линейные модели.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
